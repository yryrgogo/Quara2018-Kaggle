{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:41:43.435938Z",
     "start_time": "2018-11-08T14:41:42.774665Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-08 23:41:42,790 utils 353 [INFO]    [logger_func] start \n",
      "2018-11-08 23:41:42,790 utils 353 [INFO]    [logger_func] start \n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from utils import logger_func, pararell_process\n",
    "logger = logger_func()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:41:47.222385Z",
     "start_time": "2018-11-08T14:41:46.730063Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.32it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 182.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train = utils.read_df_pkl('../input/train*.p')\n",
    "test = utils.read_df_pkl('../input/test*.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:42:32.408266Z",
     "start_time": "2018-11-08T14:41:48.780624Z"
    }
   },
   "outputs": [],
   "source": [
    "## Split Train and Valid\n",
    "train, valid = train_test_split(train, test_size=0.1, random_state=2018)\n",
    "\n",
    "## some config values\n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "x_train = train[\"question_text\"].fillna(\"_na_\").values\n",
    "x_val = valid[\"question_text\"].fillna(\"_na_\").values\n",
    "x_test = test[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "## Pad the sentences\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = pad_sequences(x_val, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "## Get the targe values\n",
    "y_train = train[\"target\"].values\n",
    "y_val = valid[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:42:32.758843Z",
     "start_time": "2018-11-08T14:42:32.409506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          186880    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,188,961\n",
      "Trainable params: 15,188,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen, ))\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:31:42.610715Z",
     "start_time": "2018-11-08T14:42:32.760048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 1478s 1ms/step - loss: 0.1236 - acc: 0.9518 - val_loss: 0.1083 - val_acc: 0.9568\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 1471s 1ms/step - loss: 0.0988 - acc: 0.9603 - val_loss: 0.1066 - val_acc: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc9749f278>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model\n",
    "model.fit(x_train, y_train, batch_size=512, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:01:33.174521Z",
     "start_time": "2018-11-08T22:01:32.533248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5720461095100865\n",
      "F1 score at threshold 0.11 is 0.5823106915657706\n",
      "F1 score at threshold 0.12 is 0.5894745677354373\n",
      "F1 score at threshold 0.13 is 0.5971300064253587\n",
      "F1 score at threshold 0.14 is 0.6041939711664481\n",
      "F1 score at threshold 0.15 is 0.6102418207681365\n",
      "F1 score at threshold 0.16 is 0.6162596488060308\n",
      "F1 score at threshold 0.17 is 0.6210405684162272\n",
      "F1 score at threshold 0.18 is 0.6264498998462756\n",
      "F1 score at threshold 0.19 is 0.6312355194099012\n",
      "F1 score at threshold 0.2 is 0.6342140532261153\n",
      "F1 score at threshold 0.21 is 0.6373275236020334\n",
      "F1 score at threshold 0.22 is 0.6390086206896551\n",
      "F1 score at threshold 0.23 is 0.6415374708999951\n",
      "F1 score at threshold 0.24 is 0.6442408770085599\n",
      "F1 score at threshold 0.25 is 0.6455171018012548\n",
      "F1 score at threshold 0.26 is 0.6473385488571868\n",
      "F1 score at threshold 0.27 is 0.6476239669421489\n",
      "F1 score at threshold 0.28 is 0.6492720346501071\n",
      "F1 score at threshold 0.29 is 0.6501867143533373\n",
      "F1 score at threshold 0.3 is 0.6516341256366723\n",
      "F1 score at threshold 0.31 is 0.653629788373962\n",
      "F1 score at threshold 0.32 is 0.6541329011345219\n",
      "F1 score at threshold 0.33 is 0.6544919319668556\n",
      "F1 score at threshold 0.34 is 0.6555970969870244\n",
      "F1 score at threshold 0.35 is 0.6557267989799312\n",
      "F1 score at threshold 0.36 is 0.655367231638418\n",
      "F1 score at threshold 0.37 is 0.655277401894452\n",
      "F1 score at threshold 0.38 is 0.6551684881602915\n",
      "F1 score at threshold 0.39 is 0.656074337501434\n",
      "F1 score at threshold 0.4 is 0.65499104098029\n",
      "F1 score at threshold 0.41 is 0.6531802017139859\n",
      "F1 score at threshold 0.42 is 0.6524139551274521\n",
      "F1 score at threshold 0.43 is 0.6523000414421882\n",
      "F1 score at threshold 0.44 is 0.6520102754047434\n",
      "F1 score at threshold 0.45 is 0.6511375947995667\n",
      "F1 score at threshold 0.46 is 0.6506155618897447\n",
      "F1 score at threshold 0.47 is 0.6494681501406039\n",
      "F1 score at threshold 0.48 is 0.6485353068146777\n",
      "F1 score at threshold 0.49 is 0.6497108388781792\n",
      "F1 score at threshold 0.5 is 0.648506151142355\n"
     ]
    }
   ],
   "source": [
    "# y_pred_noemb_val = model.predict([x_val], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(f\"F1 score at threshold {thresh} is {metrics.f1_score(y_val, (y_pred_noemb_val>thresh).astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:05:27.859158Z",
     "start_time": "2018-11-08T22:05:07.783663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 20s 356us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_noemb_test = model.predict([x_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:06:58.830572Z",
     "start_time": "2018-11-08T22:06:58.731049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3558"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model, inp, x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:47:54.294093Z",
     "start_time": "2018-11-08T22:47:47.170431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 128)          186880    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,188,961\n",
      "Trainable params: 15,188,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = \"../model/glove.840B.300d/glove.840B.300d.txt\"\n",
    "## ここでの*arrはarrayをtubleで囲う役割になっている。listを解除する役割じゃなかったのか？謎\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in tqdm(open(EMBEDDING_FILE)) )\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "## どんな引数になってるんだ？\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "inp = Input(shape=(maxlen, ))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:37:13.127837Z",
     "start_time": "2018-11-08T22:48:39.001724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 1457s 1ms/step - loss: 0.1145 - acc: 0.9556 - val_loss: 0.1010 - val_acc: 0.9590\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 1456s 1ms/step - loss: 0.0939 - acc: 0.9626 - val_loss: 0.0997 - val_acc: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb43fe0d30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=512, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:38:35.788196Z",
     "start_time": "2018-11-08T23:38:35.141184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 i 0.5925895864615884\n",
      "F1 score at threshold 0.11 i 0.6024676997216567\n",
      "F1 score at threshold 0.12 i 0.6095173524301877\n",
      "F1 score at threshold 0.13 i 0.6171058315334773\n",
      "F1 score at threshold 0.14 i 0.6242632180874461\n",
      "F1 score at threshold 0.15 i 0.6307128163849387\n",
      "F1 score at threshold 0.16 i 0.6356328625278168\n",
      "F1 score at threshold 0.17 i 0.6399705422074933\n",
      "F1 score at threshold 0.18 i 0.6434766390002798\n",
      "F1 score at threshold 0.19 i 0.6477901205388797\n",
      "F1 score at threshold 0.2 i 0.6515412598123683\n",
      "F1 score at threshold 0.21 i 0.6544416489258758\n",
      "F1 score at threshold 0.22 i 0.6576320939334638\n",
      "F1 score at threshold 0.23 i 0.6602316602316602\n",
      "F1 score at threshold 0.24 i 0.6623701039168665\n",
      "F1 score at threshold 0.25 i 0.664276697803585\n",
      "F1 score at threshold 0.26 i 0.6670067853680934\n",
      "F1 score at threshold 0.27 i 0.6683484349258649\n",
      "F1 score at threshold 0.28 i 0.6697500389752118\n",
      "F1 score at threshold 0.29 i 0.6719127059070401\n",
      "F1 score at threshold 0.3 i 0.6725214263040948\n",
      "F1 score at threshold 0.31 i 0.6737922188969645\n",
      "F1 score at threshold 0.32 i 0.675875465386068\n",
      "F1 score at threshold 0.33 i 0.6766467065868264\n",
      "F1 score at threshold 0.34 i 0.6774264382960035\n",
      "F1 score at threshold 0.35 i 0.67764757904046\n",
      "F1 score at threshold 0.36 i 0.6777579276462705\n",
      "F1 score at threshold 0.37 i 0.678191339602455\n",
      "F1 score at threshold 0.38 i 0.6793052559881939\n",
      "F1 score at threshold 0.39 i 0.6790745619058528\n",
      "F1 score at threshold 0.4 i 0.6790102093787852\n",
      "F1 score at threshold 0.41 i 0.6784674507977175\n",
      "F1 score at threshold 0.42 i 0.6788149541500118\n",
      "F1 score at threshold 0.43 i 0.6788533444121313\n",
      "F1 score at threshold 0.44 i 0.6788002155301444\n",
      "F1 score at threshold 0.45 i 0.6776220396326728\n",
      "F1 score at threshold 0.46 i 0.6758570208612907\n",
      "F1 score at threshold 0.47 i 0.6733575518748846\n",
      "F1 score at threshold 0.48 i 0.6710199004975125\n",
      "F1 score at threshold 0.49 i 0.6702261306532664\n",
      "F1 score at threshold 0.5 i 0.6678931675442493\n"
     ]
    }
   ],
   "source": [
    "y_pred_glove_val = model.predict([x_val], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(f\"F1 score at threshold {thresh} i {metrics.f1_score(y_val, (y_pred_glove_val>thresh).astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:38:20.277234Z",
     "start_time": "2018-11-08T23:38:00.176895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 20s 357us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_glove_test = model.predict(x_test, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:39:27.588878Z",
     "start_time": "2018-11-08T23:39:27.467782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2559"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del word_index, embedding_index, all_embs, embedding_matrix, model, inp, x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = \"../model/wiki_news-300d-1M/wiki-news-300d-1M.vec\"\n",
    "## ここでの*arrはarrayをtubleで囲う役割になっている。listを解除する役割じゃなかったのか？謎\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "# len(0)>100って何？\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in tqdm(open(EMBEDDING_FILE)) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1] # 列の次元\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "## どんな引数になってるんだ？\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "inp = Input(shape=(maxlen, ))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=512, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_fasttext_val = model.predict([x_val], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(f\"F1 score at threshold {thresh} is {metrics.f1_score(y_val, (y_pred_fasttext_val>thresh).astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_fasttext_test = model.predict([x_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = \"../model/paragram_300_sl999/paragram_300_sl999.txt\"\n",
    "## ここでの*arrはarrayをtubleで囲う役割になっている。listを解除する役割じゃなかったのか？謎\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "# len(0)>100って何？\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in tqdm(open(EMBEDDING_FILE)) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1] # 列の次元\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "## どんな引数になってるんだ？\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "inp = Input(shape=(maxlen, ))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=512, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_paragram_val = model.predict([x_val], batch_size=1024, verbose=11)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(f\"F1 score at threshold {thresh} is {metrics.f1_score(y_val, (y_pred_paragram_val>thresh).astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_paragram_test = model.predict([x_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_val = 0.33*y_pred_glove_val + 0.33*y_pred_fasttext_val + 0.34+y_pred_paragram_val\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(f\"F1 score at threshold {thresh} is {metrics.f1_score(y_val, (y_pred_val>thresh).astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = 0.33*y_pred_glove_test + 0.33*y_pred_fasttext_test + 0.34*y_pred_paragram_test\n",
    "y_pred_test = (y_pred_test>0.35).astype(int)\n",
    "out_df = pd.DataFrame({\"qid\":test[\"qid\"].values})\n",
    "out_df[\"prediction\"] = y_pred_test\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
