{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the purpose of this experiment?\n",
    "LGBMをアンサンブルの1つとするにあたり、ベンチマークを作成する。\n",
    "F1 Scoreと学習に使う時間を確認する。\n",
    "また、TFIDFとEmbeddingの2通りを試す\n",
    "### 2. Why do you this?\n",
    "多様なモデルを作る為\n",
    "### 3. Where are the points of technology and techniques?\n",
    "LGBM, TFIDF or Word Embedding\n",
    "### 4. How do you validate the effectiveness?\n",
    "処理時間\n",
    "F1 Score\n",
    "### 5. What will you do next?\n",
    "NNとアンサンブルしてLBを確認する。学習時間を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T09:53:43.606080Z",
     "start_time": "2018-11-10T09:53:43.430947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import os\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "def pararell_process(func, arg_list, cpu_cnt=multiprocessing.cpu_count()):\n",
    "    process = Pool(cpu_cnt)\n",
    "    callback = process.map_async(func, arg_list).get(600)\n",
    "    process.close()\n",
    "    process.terminate()\n",
    "    return callback\n",
    "\n",
    "def mkdir_func(path):\n",
    "    try:\n",
    "        os.stat(path)\n",
    "    except:\n",
    "        os.mkdir(path)\n",
    "\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "def logger_func():\n",
    "    logger = getLogger(__name__)\n",
    "    log_fmt = Formatter('%(asctime)s %(name)s %(lineno)d [%(levelname)s]\\\n",
    "    [%(funcName)s] %(message)s ')\n",
    "    handler = StreamHandler()\n",
    "    handler.setLevel('INFO')\n",
    "    handler.setFormatter(log_fmt)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    mkdir_func('../output')\n",
    "    handler = FileHandler('../output/py_train.py.log', 'a')\n",
    "    handler.setLevel(DEBUG)\n",
    "    handler.setFormatter(log_fmt)\n",
    "    logger.setLevel(DEBUG)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    logger.info('start')\n",
    "\n",
    "    return logger\n",
    "logger = logger_func()\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    \"\"\"\n",
    "    Taken from Konstantin Lopuhin https://www.kaggle.com/lopuhin\n",
    "    in script named : Mercari Golf: 0.3875 CV in 75 LOC, 1900 s\n",
    "    https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "# NLP\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "\n",
    "key = 'qid'\n",
    "qt = 'question_text'\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleansing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contraction replacement patterns\n",
    "cont_patterns = [\n",
    "    (b'(W|w)on\\'t', b'will not'),\n",
    "    (b'(C|c)an\\'t', b'can not'),\n",
    "    (b'(I|i)\\'m', b'i am'),\n",
    "    (b'(A|a)in\\'t', b'is not'),\n",
    "    (b'(\\w+)\\'ll', b'\\g<1> will'),\n",
    "    (b'(\\w+)n\\'t', b'\\g<1> not'),\n",
    "    (b'(\\w+)\\'ve', b'\\g<1> have'),\n",
    "    (b'(\\w+)\\'s', b'\\g<1> is'),\n",
    "    (b'(\\w+)\\'re', b'\\g<1> are'),\n",
    "    (b'(\\w+)\\'d', b'\\g<1> would'),\n",
    "]\n",
    "patterns = [(re.compile(regex), repl) for (regex, repl) in cont_patterns]\n",
    "\n",
    "def prepare_for_char_n_gram(text):\n",
    "    \"\"\" Simple text clean up process\"\"\"\n",
    "    # 1. Go to lower case (only good for english)\n",
    "    # Go to bytes_strings as I had issues removing all \\n in r\"\"\n",
    "    clean = bytes(text.lower(), encoding=\"utf-8\")\n",
    "    # 2. Drop \\n and  \\t\n",
    "    clean = clean.replace(b\"\\n\", b\" \")\n",
    "    clean = clean.replace(b\"\\t\", b\" \")\n",
    "    clean = clean.replace(b\"\\b\", b\" \")\n",
    "    clean = clean.replace(b\"\\r\", b\" \")\n",
    "    # 3. Replace english contractions\n",
    "    for (pattern, repl) in patterns:\n",
    "        clean = re.sub(pattern, repl, clean)\n",
    "    # 4. Drop puntuation\n",
    "    # I could have used regex package with regex.sub(b\"\\p{P}\", \" \")\n",
    "    exclude = re.compile(b'[%s]' % re.escape(bytes(string.punctuation, encoding='utf-8')))\n",
    "    clean = b\" \".join([exclude.sub(b'', token) for token in clean.split()])\n",
    "    # 5. Drop numbers - as a scientist I don't think numbers are toxic ;-)\n",
    "    clean = re.sub(b\"\\d+\", b\" \", clean)\n",
    "    # 6. Remove extra spaces - At the end of previous operations we multiplied space accurences\n",
    "    clean = re.sub(b'\\s+', b' ', clean)\n",
    "    # Remove ending space if any\n",
    "    clean = re.sub(b'\\s+$', b'', clean)\n",
    "    # 7. Now replace words by words surrounded by # signs\n",
    "    # e.g. my name is bond would become #my# #name# #is# #bond#\n",
    "    # clean = re.sub(b\"([a-z]+)\", b\"#\\g<1>#\", clean)\n",
    "#     clean = re.sub(b\" \", b\"# #\", clean)  # Replace space\n",
    "#     clean = b\"#\" + clean + b\"#\"  # add leading and trailing #\n",
    "\n",
    "    return str(clean, 'utf-8')\n",
    "\n",
    "def count_regexp_occ(regexp=\"\", text=None):\n",
    "    \"\"\" Simple way to get the number of occurence of a regex\"\"\"\n",
    "    return len(re.findall(regexp, text))\n",
    "\n",
    "def cleansing_text(text, remove_stopwords=True):\n",
    "\n",
    "    # Convert words to lower case and split them\n",
    "    text = re.sub(\"_\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = text.lower().split()\n",
    "    regex_num = re.compile(u\"[0-9０-９]\")\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = STOPWORDS\n",
    "        text = [w for w in text if (not w in stops) and not(regex_num.match(w))]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text)\n",
    "    text = re.sub(\"\\'d\", \" would \", text)\n",
    "    text = re.sub(\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(\"\\'re\", \" are \", text)\n",
    "    text = re.sub(\"\\'s\", \" \", text) # we have cases like \"Sam is\" or \"Sam's\" (i.e. his) these two cases aren't separable, I choose to compromise are kill \"'s\" directly\n",
    "    text = re.sub(\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(\"\\(s\\)\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"e-mail\", \" email \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(\"b\\.g\\.\", \" bg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"…\", \" \", text)\n",
    "    text = re.sub(\"？\", \"?\", text)\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
    "    text = re.sub('\\$', \" dollar \", text)\n",
    "    text = re.sub('\\%', \" percent \", text)\n",
    "    text = re.sub('\\&', \" and \", text)\n",
    "    \n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\W|^)([0-9]+)[kK](\\W|$)\", r\"\\1\\g<2>000\\3\", text) # better regex provided by @armamut\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "\n",
    "    # Original\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" (the[\\s]+|The[\\s]+)?US(A)? \", \" America \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" india \", \" India \", text)\n",
    "    text = re.sub(r\" switzerland \", \" Switzerland \", text)\n",
    "    text = re.sub(r\" china \", \" China \", text)\n",
    "    text = re.sub(r\" chinese \", \" Chinese \", text)\n",
    "    text = re.sub(r\" quora \", \" Quora \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" qoura \", \" Quora \", text)\n",
    "    text = re.sub(r\" upvote\", \" up vote\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J K \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"(?=[a-zA-Z])ig \", \"ing \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How did Quebec nationalists see their province as a nation in the 1960s?', 'Do you have an adopted dog, how would you encourage people to adopt and not shop?', 'Why does velocity affect time? Does velocity affect space geometry?', 'How did Otto von Guericke used the Magdeburg hemispheres?', 'Can I convert montra helicon D to a mountain bike by just changing the tyres?', 'Is Gaza slowly becoming Auschwitz, Dachau or Treblinka for Palestinians?', 'Why does Quora automatically ban conservative opinions when reported, but does not do the same for liberal views?', 'Is it crazy if I wash or wipe my groceries off? Germs are everywhere.', 'Is there such a thing as dressing moderately, and if so, how is that different than dressing modestly?', 'Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved, completely disregarding their feelings/lives so you get to have something go your way and feel temporarily at ease. How did things change?']\n"
     ]
    }
   ],
   "source": [
    "def quara_load_data():\n",
    "    train = pd.read_csv('../input/train.csv')\n",
    "    test = pd.read_csv('../input/test.csv')\n",
    "    # read pickle\n",
    "#     train = utils.read_df_pkl(path='../input/train*.p')\n",
    "#     test = utils.read_df_pkl(path='../input/test*.p')\n",
    "    return train, test\n",
    "\n",
    "train, test = quara_load_data()\n",
    "# Load id Text List\n",
    "train_id_list = list(train[key].values)\n",
    "test_id_list = list(test[key].values)\n",
    "train_text_list = list(train[qt].values)\n",
    "test_text_list = list(test[qt].values)\n",
    "id_list = train_id_list + test_id_list\n",
    "text_list = train_text_list + test_text_list\n",
    "\n",
    "raw_trn_idx = train.index\n",
    "raw_test_idx = test.index\n",
    "y = train[target]\n",
    "\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "print(train_text_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleansing Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cleansing Dataset] done in 56 s\n"
     ]
    }
   ],
   "source": [
    "# Cleansing\n",
    "with timer(\"Cleansing Dataset\"):\n",
    "    # 並列処理でクレンジング\n",
    "    train_text_list = Parallel(n_jobs=-1)( [delayed(cleansing_text)(args) for args in train_text_list] )\n",
    "    train_text_list = Parallel(n_jobs=-1)( [delayed(prepare_for_char_n_gram)(args) for args in train_text_list] )\n",
    "    test_text_list = Parallel(n_jobs=-1)( [delayed(cleansing_text)(args) for args in test_text_list] )\n",
    "    test_text_list = Parallel(n_jobs=-1)( [delayed(prepare_for_char_n_gram)(args) for args in test_text_list] )\n",
    "    text_list = train_text_list + test_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF\n",
    "ngramはいくつかパターンを試す\n",
    "実験のため、tfidf matrixとvecotorizerは保存しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fitting TFIDF] done in 11 s\n",
      "[Transform TFIDF] done in 10 s\n"
     ]
    }
   ],
   "source": [
    "ngram_range=(1,1)\n",
    "# ngram_range=(1,2)\n",
    "\n",
    "def get_tfidf(text_list):\n",
    "    '''\n",
    "    Explain:\n",
    "        テキストを1要素としてもったリストを渡し、TFIDFベクトルをもったsparse matrixを出力する\n",
    "    Args:\n",
    "        text_list(list): split前のテキストリスト. 1テキストが1つのTFIDFベクトルに変換される\n",
    "    Return:\n",
    "        sparse csr_matrix: TFIDF値が入ったスパースな行列\n",
    "    '''\n",
    "    # Get the tfidf\n",
    "    with timer(\"Fitting TFIDF\"):\n",
    "        # TFIDFに変換するオブジェクトを作成する\n",
    "        tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features = 10000,\n",
    "            min_df=10,\n",
    "            max_df=0.5,\n",
    "            stop_words=\"english\",\n",
    "            analyzer='word',\n",
    "            #  analyzer='char',\n",
    "            strip_accents='unicode',\n",
    "            ngram_range=ngram_range,\n",
    "            use_idf=True,\n",
    "            smooth_idf=True,\n",
    "            sublinear_tf=True\n",
    "        ).fit(text_list)\n",
    "\n",
    "    # Train, Testのテキストが順番に並んだリストを渡すと、各テキストをTFIDFベクトルに変換して返してくれる\n",
    "    # テキストに対応するインデックスを渡して返ってくるのが対応するTFIDFベクトル\n",
    "    with timer(\"Transform TFIDF\"):\n",
    "        csr_tfidf = tfidf_vectorizer.transform(text_list)\n",
    "    return csr_tfidf, tfidf_vectorizer\n",
    "\n",
    "# TFIDF\n",
    "csr_tfidf, tfidf_vectorizer = get_tfidf(text_list)\n",
    "# del text_list\n",
    "# gc.collect()\n",
    "utils.to_pkl_gzip(obj=tfidf_vectorizer, path='../input/bench_vectorizer_tfidf30000.gz')\n",
    "utils.to_pkl_gzip(obj=csr_tfidf, path='../input/bench_csr_tfidf30000.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM Setting] done in 0 s\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.14981\n",
      "[400]\tvalid_0's binary_logloss: 0.14224\n",
      "[600]\tvalid_0's binary_logloss: 0.138298\n",
      "[800]\tvalid_0's binary_logloss: 0.135741\n",
      "[1000]\tvalid_0's binary_logloss: 0.133967\n",
      "[1200]\tvalid_0's binary_logloss: 0.132709\n",
      "[1400]\tvalid_0's binary_logloss: 0.131722\n",
      "[1600]\tvalid_0's binary_logloss: 0.130938\n",
      "[1800]\tvalid_0's binary_logloss: 0.130321\n",
      "[2000]\tvalid_0's binary_logloss: 0.129813\n",
      "[2200]\tvalid_0's binary_logloss: 0.1294\n",
      "[2400]\tvalid_0's binary_logloss: 0.129081\n",
      "[2600]\tvalid_0's binary_logloss: 0.128801\n",
      "[2800]\tvalid_0's binary_logloss: 0.128563\n",
      "[3000]\tvalid_0's binary_logloss: 0.128355\n",
      "[3200]\tvalid_0's binary_logloss: 0.128187\n",
      "[3400]\tvalid_0's binary_logloss: 0.128061\n",
      "[3600]\tvalid_0's binary_logloss: 0.127972\n",
      "[3800]\tvalid_0's binary_logloss: 0.127881\n",
      "[4000]\tvalid_0's binary_logloss: 0.127797\n",
      "[4200]\tvalid_0's binary_logloss: 0.127758\n",
      "[4400]\tvalid_0's binary_logloss: 0.127736\n",
      "[4600]\tvalid_0's binary_logloss: 0.127719\n",
      "Early stopping, best iteration is:\n",
      "[4582]\tvalid_0's binary_logloss: 0.127714\n",
      "[Validation: 0 | LGBM Train] done in 142 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 14:43:23,992 __main__ 78 [INFO]    [<module>] Fold No: 0 | accuracy: 0.12771381523618552 \n",
      "2018-11-25 14:43:23,993 __main__ 79 [INFO]    [<module>] Train Shape: (653061, 10000) \n",
      "2018-11-25 14:43:24,097 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.1 is 0.54434276415672 \n",
      "2018-11-25 14:43:24,198 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.11 is 0.5539917516822227 \n",
      "2018-11-25 14:43:24,302 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.12 is 0.5610724302624622 \n",
      "2018-11-25 14:43:24,403 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.13 is 0.5677558666383679 \n",
      "2018-11-25 14:43:24,507 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.14 is 0.5731884126638176 \n",
      "2018-11-25 14:43:24,609 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.15 is 0.577647356044853 \n",
      "2018-11-25 14:43:24,708 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.16 is 0.5815484358530717 \n",
      "2018-11-25 14:43:24,813 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.17 is 0.5839596960955592 \n",
      "2018-11-25 14:43:24,912 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.18 is 0.5859850172519194 \n",
      "2018-11-25 14:43:25,018 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.19 is 0.5871201325775568 \n",
      "2018-11-25 14:43:25,115 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.2 is 0.5888012025554303 \n",
      "2018-11-25 14:43:25,212 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.21 is 0.5895948706185624 \n",
      "2018-11-25 14:43:25,311 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.22 is 0.5899179991344969 \n",
      "2018-11-25 14:43:25,409 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.23 is 0.5900190510545718 \n",
      "2018-11-25 14:43:25,507 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.24 is 0.5892871452611816 \n",
      "2018-11-25 14:43:25,608 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.25 is 0.5891890636251713 \n",
      "2018-11-25 14:43:25,707 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.26 is 0.5888217202248383 \n",
      "2018-11-25 14:43:25,809 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.27 is 0.5874177641397921 \n",
      "2018-11-25 14:43:25,907 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.28 is 0.5860479744523341 \n",
      "2018-11-25 14:43:26,004 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.29 is 0.584844623076169 \n",
      "2018-11-25 14:43:26,103 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.3 is 0.5830654869013787 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation: 0 | Prediction & Get F1 score] done in 25 s\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.149456\n",
      "[400]\tvalid_0's binary_logloss: 0.141828\n",
      "[600]\tvalid_0's binary_logloss: 0.13796\n",
      "[800]\tvalid_0's binary_logloss: 0.135506\n",
      "[1000]\tvalid_0's binary_logloss: 0.133699\n",
      "[1200]\tvalid_0's binary_logloss: 0.132409\n",
      "[1400]\tvalid_0's binary_logloss: 0.131451\n",
      "[1600]\tvalid_0's binary_logloss: 0.130673\n",
      "[1800]\tvalid_0's binary_logloss: 0.130056\n",
      "[2000]\tvalid_0's binary_logloss: 0.129535\n",
      "[2200]\tvalid_0's binary_logloss: 0.129128\n",
      "[2400]\tvalid_0's binary_logloss: 0.128782\n",
      "[2600]\tvalid_0's binary_logloss: 0.128529\n",
      "[2800]\tvalid_0's binary_logloss: 0.128282\n",
      "[3000]\tvalid_0's binary_logloss: 0.12811\n",
      "[3200]\tvalid_0's binary_logloss: 0.127932\n",
      "[3400]\tvalid_0's binary_logloss: 0.127828\n",
      "[3600]\tvalid_0's binary_logloss: 0.127728\n",
      "[3800]\tvalid_0's binary_logloss: 0.127647\n",
      "[4000]\tvalid_0's binary_logloss: 0.127585\n",
      "[4200]\tvalid_0's binary_logloss: 0.127555\n",
      "[4400]\tvalid_0's binary_logloss: 0.127533\n",
      "Early stopping, best iteration is:\n",
      "[4425]\tvalid_0's binary_logloss: 0.127521\n",
      "[Validation: 1 | LGBM Train] done in 134 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 14:46:02,457 __main__ 78 [INFO]    [<module>] Fold No: 1 | accuracy: 0.1275211864423686 \n",
      "2018-11-25 14:46:02,458 __main__ 79 [INFO]    [<module>] Train Shape: (653061, 10000) \n",
      "2018-11-25 14:46:02,565 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.1 is 0.5433394045710545 \n",
      "2018-11-25 14:46:02,664 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.11 is 0.5525327677919549 \n",
      "2018-11-25 14:46:02,766 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.12 is 0.5605704547493049 \n",
      "2018-11-25 14:46:02,872 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.13 is 0.5671630760134511 \n",
      "2018-11-25 14:46:02,976 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.14 is 0.5727147798891153 \n",
      "2018-11-25 14:46:03,081 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.15 is 0.5774877650897227 \n",
      "2018-11-25 14:46:03,184 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.16 is 0.5807072551198603 \n",
      "2018-11-25 14:46:03,285 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.17 is 0.583711095561167 \n",
      "2018-11-25 14:46:03,388 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.18 is 0.5861512688465595 \n",
      "2018-11-25 14:46:03,486 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.19 is 0.5879959093736492 \n",
      "2018-11-25 14:46:03,582 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.2 is 0.5889511299980683 \n",
      "2018-11-25 14:46:03,677 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.21 is 0.5898373939347611 \n",
      "2018-11-25 14:46:03,772 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.22 is 0.590570940019098 \n",
      "2018-11-25 14:46:03,867 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.23 is 0.591078318554119 \n",
      "2018-11-25 14:46:03,969 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.24 is 0.5910261841246579 \n",
      "2018-11-25 14:46:04,073 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.25 is 0.5904905835852127 \n",
      "2018-11-25 14:46:04,175 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.26 is 0.5899604789712736 \n",
      "2018-11-25 14:46:04,275 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.27 is 0.5889187735341582 \n",
      "2018-11-25 14:46:04,369 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.28 is 0.5877607384257576 \n",
      "2018-11-25 14:46:04,463 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.29 is 0.5872192165666825 \n",
      "2018-11-25 14:46:04,563 __main__ 83 [INFO]    [<module>] F1 score at threshold 0.3 is 0.5857966118535447 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation: 1 | Prediction & Get F1 score] done in 25 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0_importance</th>\n",
       "      <th>1_importance</th>\n",
       "      <th>avg_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>people</td>\n",
       "      <td>34242.119384</td>\n",
       "      <td>35138.043894</td>\n",
       "      <td>34690.081639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9303</th>\n",
       "      <td>trump</td>\n",
       "      <td>32804.123573</td>\n",
       "      <td>21802.197533</td>\n",
       "      <td>27303.160553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9887</th>\n",
       "      <td>women</td>\n",
       "      <td>29830.597529</td>\n",
       "      <td>19303.307746</td>\n",
       "      <td>24566.952638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>muslims</td>\n",
       "      <td>19038.931980</td>\n",
       "      <td>21989.020672</td>\n",
       "      <td>20513.976326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>americans</td>\n",
       "      <td>19389.520050</td>\n",
       "      <td>18971.808566</td>\n",
       "      <td>19180.664308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  0_importance  1_importance  avg_importance\n",
       "6559     people  34242.119384  35138.043894    34690.081639\n",
       "9303      trump  32804.123573  21802.197533    27303.160553\n",
       "9887      women  29830.597529  19303.307746    24566.952638\n",
       "5912    muslims  19038.931980  21989.020672    20513.976326\n",
       "344   americans  19389.520050  18971.808566    19180.664308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAK7CAYAAAAgH4+fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYMTMzMwK5WDEzMzMCvV/e08uNTvt1YcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8f3ff6828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selece Feature: 2020\n",
      "[Save Feature Importance] done in 0 s\n",
      "2020\n",
      "['aap', 'ability', 'able', 'abortion', 'abortions', 'abuse', 'abusing', 'accept', 'acceptable', 'according', 'account', 'acknowledge', 'act', 'acting', 'actions', 'active', 'activists', 'actually', 'adam', 'add', 'address', 'administration', 'admission', 'admit', 'adolf', 'adopt', 'ads', 'adult', 'adults', 'advantages', 'advice', 'affairs', 'affect', 'affected', 'affirmative', 'afghan', 'afraid', 'africa', 'african', 'africans', 'age', 'agenda', 'agents', 'aggressive', 'ago', 'agree', 'aids', 'air', 'aircraft', 'aka', 'al', 'albanians', 'alex', 'alien', 'aliens', 'alive', 'allah', 'allow', 'allowed', 'allowing', 'alt', 'amazon', 'amendment', 'america', 'american', 'americans', 'anal', 'analysis', 'ancestors', 'ancient', 'android', 'angry', 'animal', 'animals', 'anime', 'annoy', 'annoying', 'answer', 'answers', 'anti', 'antifa', 'anus', 'anxiety', 'anybody', 'apart', 'apartheid', 'apologize', 'app', 'apparently', 'application', 'apply', 'approach', 'apps', 'ar', 'arab', 'arabs', 'area', 'aren', 'argue', 'army', 'arrogant', 'art', 'arts', 'ashamed', 'asia', 'asian', 'asians', 'ask', 'asked', 'asking', 'asperger', 'ass', 'assad', 'assassinated', 'assassination', 'assault', 'asshole', 'assholes', 'assume', 'ate', 'atheism', 'atheist', 'atheists', 'attack', 'attacking', 'attacks', 'attracted', 'attractive', 'aunt', 'australia', 'australian', 'australians', 'autism', 'autistic', 'available', 'average', 'avoid', 'aware', 'away', 'ayurveda', 'ayurvedic', 'babies', 'baby', 'background', 'backward', 'bad', 'badly', 'balls', 'ban', 'bang', 'bangladesh', 'bangladeshis', 'bank', 'banned', 'barack', 'bare', 'barry', 'based', 'bashing', 'basically', 'bathroom', 'battery', 'battle', 'beat', 'beaten', 'beautiful', 'beauty', 'bed', 'beg', 'behave', 'behavior', 'belief', 'beliefs', 'believe', 'believers', 'believing', 'belly', 'benefit', 'benefits', 'bengal', 'bengali', 'bengalis', 'bernie', 'best', 'better', 'bf', 'bhakts', 'biased', 'bible', 'bigger', 'biggest', 'bigoted', 'bihar', 'bike', 'bikini', 'billion', 'bing', 'birth', 'bisexual', 'bitch', 'bitcoin', 'bjp', 'black', 'blacks', 'blame', 'blind', 'blindly', 'block', 'blog', 'blood', 'bloody', 'blow', 'blue', 'board', 'bodies', 'body', 'bollywood', 'bomb', 'bombing', 'bombs', 'boobs', 'book', 'books', 'border', 'boring', 'born', 'boy', 'boyfriend', 'boys', 'bra', 'brahmin', 'brahmins', 'brain', 'brains', 'brainwashed', 'brainwashing', 'branch', 'brand', 'brazilians', 'bread', 'break', 'breasts', 'breed', 'brexit', 'britain', 'british', 'brits', 'brother', 'brothers', 'brought', 'brown', 'brutal', 'buddhists', 'budget', 'build', 'building', 'bullshit', 'bully', 'bunch', 'burn', 'bush', 'business', 'butt', 'buy', 'buying', 'ca', 'calculate', 'california', 'called', 'calling', 'came', 'camps', 'canada', 'canadian', 'canadians', 'cancer', 'candidate', 'car', 'card', 'care', 'career', 'cares', 'carry', 'cars', 'case', 'cases', 'caste', 'castrate', 'castrated', 'castration', 'cat', 'catholic', 'catholics', 'caught', 'cause', 'caused', 'causes', 'cbse', 'celebrities', 'certain', 'challenges', 'chance', 'chances', 'change', 'changed', 'changes', 'character', 'characteristics', 'characters', 'charles', 'chat', 'cheat', 'cheating', 'check', 'chemical', 'chemistry', 'chest', 'child', 'childish', 'children', 'china', 'chinese', 'choose', 'christ', 'christian', 'christianity', 'christians', 'chromosomes', 'church', 'churches', 'cia', 'cities', 'citizen', 'citizens', 'citizenship', 'city', 'civil', 'civilians', 'civilized', 'claim', 'claimed', 'claiming', 'claims', 'class', 'classes', 'clearly', 'climate', 'clinton', 'close', 'closet', 'cnn', 'coaching', 'cocaine', 'cock', 'code', 'college', 'colleges', 'color', 'colour', 'columbia', 'come', 'comes', 'coming', 'comments', 'commit', 'committed', 'committing', 'common', 'communism', 'communist', 'communists', 'community', 'companies', 'company', 'compare', 'compared', 'complain', 'complaining', 'computer', 'conditions', 'confident', 'conflict', 'congress', 'consent', 'conservative', 'conservatives', 'consider', 'considered', 'considering', 'conspiracy', 'constantly', 'constitution', 'contact', 'content', 'context', 'continue', 'control', 'controlled', 'conversation', 'convince', 'cope', 'cops', 'correctness', 'corrupt', 'corruption', 'cost', 'countries', 'country', 'course', 'courses', 'court', 'cousin', 'cousins', 'cow', 'coward', 'cows', 'crap', 'crazy', 'create', 'credit', 'crime', 'crimes', 'criminal', 'criminals', 'cruel', 'crush', 'crying', 'cs', 'cse', 'cult', 'culture', 'cultures', 'cum', 'cup', 'currency', 'current', 'currently', 'cut', 'cyprus', 'dad', 'daddy', 'dalit', 'dalits', 'damage', 'damn', 'dare', 'dark', 'darwin', 'data', 'date', 'dating', 'daughter', 'daughters', 'david', 'day', 'days', 'dead', 'deal', 'death', 'deaths', 'debate', 'decades', 'decide', 'decision', 'define', 'degree', 'deliberately', 'delusional', 'demand', 'democracy', 'democrat', 'democratic', 'democrats', 'denial', 'deny', 'denying', 'deport', 'depressed', 'depression', 'deserve', 'design', 'desperate', 'despise', 'despite', 'destroy', 'destroyed', 'destroying', 'destruction', 'determine', 'develop', 'development', 'devil', 'dick', 'dictator', 'didn', 'die', 'died', 'dies', 'diet', 'differ', 'difference', 'differences', 'different', 'differently', 'digital', 'direct', 'dirty', 'disabilities', 'disabled', 'disadvantages', 'discriminate', 'discrimination', 'disgusted', 'disgusting', 'dishonest', 'dislike', 'disorder', 'disrespect', 'distance', 'divorce', 'dnc', 'doctors', 'doctrine', 'doesn', 'dog', 'dogs', 'dollar', 'dollars', 'dominated', 'don', 'donald', 'dont', 'double', 'download', 'dream', 'dressed', 'drink', 'drive', 'drivers', 'drug', 'dubai', 'dumb', 'dumbest', 'dump', 'early', 'earn', 'earth', 'earthers', 'easily', 'east', 'easy', 'eat', 'eating', 'economic', 'economy', 'educated', 'education', 'effect', 'effective', 'effects', 'ego', 'egyptians', 'elect', 'election', 'elizabeth', 'elon', 'email', 'end', 'energy', 'engineer', 'engineering', 'engineers', 'england', 'english', 'enjoy', 'enter', 'entirely', 'entitled', 'environment', 'equal', 'equality', 'era', 'erect', 'erection', 'escort', 'especially', 'estate', 'ethnic', 'ethnicities', 'eu', 'europe', 'european', 'europeans', 'evangelicals', 'events', 'eventually', 'everybody', 'everyday', 'evidence', 'evil', 'evolution', 'ex', 'exactly', 'exam', 'example', 'examples', 'exams', 'excuse', 'exist', 'existence', 'expect', 'expensive', 'experience', 'experienced', 'experiences', 'explain', 'extreme', 'extremist', 'eye', 'eyes', 'face', 'facebook', 'fact', 'factors', 'facts', 'failed', 'fair', 'fake', 'false', 'families', 'family', 'famous', 'fans', 'far', 'fart', 'fascism', 'fascist', 'fast', 'faster', 'fat', 'father', 'fathers', 'fault', 'favorite', 'favourite', 'fbi', 'fear', 'feature', 'features', 'feel', 'feeling', 'feelings', 'feet', 'female', 'females', 'feminism', 'feminist', 'feminists', 'fetus', 'field', 'file', 'filipino', 'filipinos', 'filled', 'film', 'finally', 'finger', 'firearms', 'flag', 'flat', 'flesh', 'fly', 'flying', 'folks', 'follow', 'followers', 'food', 'foods', 'fool', 'foolish', 'fools', 'football', 'force', 'forced', 'forcing', 'foreign', 'foreigners', 'forget', 'form', 'formed', 'forms', 'fox', 'france', 'fraud', 'free', 'freedom', 'french', 'friend', 'friends', 'friendship', 'fuck', 'fucked', 'fucking', 'fun', 'function', 'funny', 'future', 'gain', 'game', 'gandhi', 'gang', 'garbage', 'gave', 'gay', 'gays', 'gaza', 'gender', 'genders', 'general', 'generally', 'generation', 'genetic', 'genitals', 'genius', 'genocide', 'george', 'german', 'germans', 'germany', 'getting', 'giant', 'girl', 'girlfriend', 'girlfriends', 'girls', 'given', 'gives', 'giving', 'global', 'globe', 'goat', 'god', 'gods', 'going', 'gold', 'golden', 'gone', 'good', 'google', 'gop', 'got', 'government', 'governments', 'grab', 'grandma', 'great', 'greece', 'greedy', 'greek', 'greeks', 'green', 'group', 'groups', 'grow', 'gst', 'guilty', 'gujarati', 'gun', 'guns', 'guy', 'guys', 'hair', 'half', 'hamas', 'hand', 'handle', 'happen', 'happened', 'happens', 'happy', 'harass', 'hard', 'harry', 'harvard', 'harvey', 'hate', 'hated', 'hateful', 'haters', 'hating', 'hatred', 'hawking', 'head', 'heads', 'health', 'healthcare', 'healthy', 'hear', 'heart', 'heat', 'heaven', 'hell', 'help', 'hide', 'hiding', 'high', 'higher', 'hillary', 'hindi', 'hindu', 'hinduism', 'hindus', 'hire', 'hispanic', 'hispanics', 'historical', 'history', 'hit', 'hitler', 'hoax', 'hole', 'holes', 'hollywood', 'holocaust', 'holy', 'home', 'homeland', 'homeless', 'homo', 'homophobic', 'homosexual', 'homosexuality', 'homosexuals', 'honest', 'horny', 'horrible', 'horse', 'hostel', 'hostile', 'hot', 'hours', 'house', 'huge', 'human', 'humanity', 'humans', 'hunt', 'hurt', 'husband', 'husbands', 'hyderabad', 'hypocrisy', 'hypocrite', 'hypocrites', 'hypocritical', 'idea', 'ideal', 'ideas', 'identify', 'identity', 'idiot', 'idiotic', 'idiots', 'ignorance', 'ignorant', 'ignore', 'iitians', 'ill', 'illegal', 'illegally', 'illegals', 'illiterate', 'illness', 'illogical', 'illuminati', 'immature', 'immigrants', 'immigration', 'immoral', 'impact', 'importance', 'important', 'improve', 'incapable', 'incest', 'inch', 'inches', 'incompetent', 'incorrect', 'increase', 'increased', 'india', 'indian', 'indians', 'individuals', 'indonesian', 'indonesians', 'industry', 'inferior', 'inferiority', 'influence', 'influenced', 'innocent', 'insane', 'insecure', 'inside', 'insist', 'inspired', 'instagram', 'instead', 'insult', 'insulting', 'intellect', 'intellectual', 'intellectually', 'intellectuals', 'intelligence', 'intelligent', 'intercourse', 'interested', 'interesting', 'international', 'internet', 'interracial', 'interview', 'intolerant', 'invade', 'invent', 'invented', 'invest', 'investment', 'iq', 'iqs', 'iran', 'iranian', 'iranians', 'iraq', 'ireland', 'irish', 'irrational', 'irritating', 'isis', 'islam', 'islamic', 'isn', 'israel', 'israeli', 'israelis', 'issue', 'italian', 'italians', 'jabba', 'jail', 'japan', 'japanese', 'java', 'jealous', 'jee', 'jeff', 'jehovah', 'jerk', 'jesus', 'jew', 'jewish', 'jews', 'jinping', 'job', 'jobs', 'john', 'join', 'joke', 'jones', 'jong', 'journalists', 'judaism', 'justice', 'justify', 'justin', 'kannada', 'kannadigas', 'kapoor', 'karnataka', 'kashmir', 'kashmiri', 'kashmiris', 'kate', 'kejriwal', 'kerala', 'khan', 'kick', 'kicked', 'kid', 'kids', 'kill', 'killed', 'killer', 'killers', 'killing', 'killings', 'kim', 'kind', 'king', 'kkk', 'knew', 'know', 'known', 'korea', 'korean', 'koreans', 'kurdish', 'kurds', 'labeled', 'lack', 'ladies', 'lady', 'land', 'landing', 'language', 'languages', 'laptop', 'large', 'later', 'latin', 'latinos', 'law', 'laws', 'lazy', 'leaders', 'learn', 'learning', 'leave', 'left', 'leftist', 'leftists', 'legal', 'leia', 'lesbian', 'lesbians', 'let', 'letter', 'letting', 'level', 'lgbt', 'lgbtq', 'liar', 'liars', 'liberal', 'liberalism', 'liberals', 'libertarians', 'license', 'lick', 'lie', 'lied', 'lies', 'life', 'light', 'likely', 'line', 'list', 'little', 'live', 'lives', 'living', 'lizard', 'loan', 'logical', 'lol', 'long', 'look', 'looked', 'looking', 'looks', 'lose', 'loser', 'losers', 'lost', 'lot', 'loud', 'love', 'lovers', 'low', 'lower', 'loyal', 'lying', 'macedonia', 'machine', 'mad', 'main', 'mainland', 'major', 'majority', 'make', 'makes', 'making', 'malays', 'malaysians', 'male', 'males', 'man', 'management', 'manaphy', 'mangalore', 'manners', 'mao', 'marathi', 'market', 'marketing', 'markle', 'marks', 'marriage', 'married', 'marry', 'mass', 'massacre', 'masturbate', 'masturbating', 'match', 'math', 'mathematicians', 'maths', 'matter', 'maybe', 'mba', 'mbbs', 'mccain', 'mean', 'meaning', 'means', 'meant', 'measure', 'meat', 'mecca', 'mechanical', 'media', 'medical', 'meet', 'meeting', 'meetup', 'meghan', 'melania', 'member', 'members', 'memory', 'men', 'mental', 'mentality', 'mentally', 'merkel', 'mess', 'message', 'messages', 'met', 'metal', 'mexican', 'mexicans', 'mexico', 'middle', 'migrants', 'military', 'millennials', 'million', 'millions', 'mind', 'minded', 'minds', 'minorities', 'minority', 'miserable', 'missionaries', 'mobile', 'mock', 'model', 'moderation', 'moderators', 'modern', 'modi', 'molested', 'mom', 'moment', 'moms', 'money', 'mongolia', 'mongolian', 'monkey', 'monkeys', 'monster', 'month', 'months', 'moon', 'moore', 'moral', 'morals', 'mormon', 'mormons', 'mother', 'mothers', 'mouth', 'movement', 'movie', 'movies', 'moving', 'mr', 'mueller', 'muhammad', 'mum', 'mumbai', 'murder', 'murdered', 'murderer', 'murderers', 'murdering', 'murders', 'muscle', 'music', 'musk', 'muslim', 'muslims', 'nadu', 'naive', 'naked', 'names', 'nancy', 'narcissists', 'narendra', 'nasa', 'nasty', 'nation', 'national', 'nationalists', 'nations', 'native', 'natives', 'natural', 'nature', 'navel', 'nazi', 'nazis', 'nazism', 'necessary', 'need', 'needs', 'neet', 'nehru', 'neighbor', 'neighbors', 'nepal', 'nepalese', 'network', 'new', 'news', 'nfl', 'nice', 'nigerian', 'nigerians', 'night', 'nobel', 'non', 'nonsense', 'normal', 'north', 'noticed', 'novel', 'nowadays', 'nra', 'nuclear', 'nude', 'nuke', 'nukes', 'number', 'obama', 'obamacare', 'obese', 'obesity', 'obsessed', 'obvious', 'obviously', 'offended', 'offer', 'office', 'officer', 'oh', 'oil', 'ok', 'okay', 'old', 'older', 'ones', 'online', 'open', 'opinion', 'opinions', 'opposite', 'oppressed', 'option', 'options', 'orange', 'order', 'organs', 'orthodox', 'outside', 'overcome', 'overweight', 'owned', 'owners', 'paid', 'pain', 'pakistan', 'pakistani', 'pakistanis', 'palestine', 'palestinian', 'palestinians', 'panther', 'panties', 'pants', 'paper', 'parent', 'parents', 'partner', 'party', 'pass', 'past', 'pathetic', 'patriotic', 'paul', 'pay', 'peace', 'pedophile', 'pedophiles', 'pedophilia', 'pee', 'penis', 'penises', 'people', 'peoples', 'percent', 'percentage', 'performance', 'period', 'persians', 'person', 'personal', 'personality', 'persons', 'phone', 'physically', 'physics', 'pigs', 'ping', 'pink', 'piss', 'place', 'places', 'plan', 'planet', 'play', 'player', 'playing', 'pm', 'point', 'poison', 'police', 'policies', 'policy', 'polish', 'political', 'politically', 'politicians', 'politics', 'poop', 'poor', 'poorly', 'pope', 'popular', 'population', 'porn', 'positive', 'possible', 'post', 'potential', 'potter', 'potus', 'poverty', 'power', 'powerful', 'prefer', 'pregnancy', 'pregnant', 'prepare', 'present', 'presidency', 'president', 'presidents', 'pressure', 'pretend', 'pretending', 'pretentious', 'pretty', 'prevent', 'price', 'pride', 'priest', 'priests', 'prime', 'prince', 'princess', 'prison', 'privilege', 'pro', 'probability', 'problem', 'problems', 'procedure', 'process', 'produce', 'produced', 'product', 'products', 'professors', 'profile', 'program', 'programming', 'progressives', 'project', 'promoting', 'proof', 'propaganda', 'prophet', 'pros', 'prosecuted', 'prostitute', 'prostitutes', 'prostitution', 'protect', 'protest', 'proud', 'prove', 'proven', 'provide', 'pseudo', 'psychology', 'psychopath', 'psychopaths', 'public', 'puerto', 'punch', 'punish', 'punishment', 'punjabi', 'puppet', 'purpose', 'pursue', 'pussy', 'putin', 'quality', 'queen', 'question', 'questions', 'quora', 'quoran', 'quorans', 'quran', 'race', 'races', 'racial', 'racism', 'racist', 'racists', 'radical', 'rahul', 'range', 'rank', 'rape', 'raped', 'rapes', 'raping', 'rapist', 'rapists', 'rate', 'ratio', 'reach', 'react', 'reaction', 'read', 'real', 'realise', 'reality', 'realize', 'really', 'reason', 'reasons', 'received', 'recent', 'recommend', 'red', 'reduce', 'refugees', 'refuse', 'regarding', 'regime', 'regret', 'regular', 'related', 'relationship', 'religion', 'religions', 'religious', 'remove', 'republic', 'republican', 'republicans', 'required', 'research', 'reservation', 'residents', 'respect', 'respectful', 'respond', 'response', 'responsibility', 'responsible', 'rest', 'return', 'revealing', 'revenge', 'revolution', 'rice', 'rich', 'rid', 'ridiculous', 'right', 'rights', 'rise', 'road', 'rohingya', 'role', 'romanian', 'round', 'royal', 'rss', 'rude', 'ruin', 'ruining', 'rule', 'rules', 'run', 'running', 'russia', 'russian', 'russians', 'sacrifice', 'sad', 'safe', 'said', 'salary', 'sales', 'sanders', 'satan', 'saudi', 'save', 'saw', 'say', 'saying', 'says', 'sc', 'scam', 'scared', 'scene', 'school', 'schools', 'science', 'scientific', 'scientists', 'scope', 'score', 'scottish', 'screaming', 'screen', 'screw', 'search', 'season', 'second', 'secret', 'secretly', 'security', 'seduce', 'seen', 'selected', 'self', 'selfish', 'sell', 'semen', 'semi', 'send', 'sending', 'sense', 'sensitive', 'sent', 'sentence', 'separated', 'serbs', 'series', 'seriously', 'service', 'services', 'set', 'sex', 'sexism', 'sexist', 'sexual', 'sexually', 'sexy', 'shallow', 'shame', 'shameless', 'share', 'sharia', 'sheep', 'shia', 'shias', 'shit', 'shithole', 'shoot', 'shooter', 'shooters', 'shooting', 'shootings', 'short', 'shot', 'shouldn', 'shower', 'shows', 'shut', 'shy', 'sick', 'sides', 'sign', 'significance', 'significant', 'signs', 'sikh', 'sikhs', 'silly', 'similar', 'simply', 'sin', 'singaporeans', 'singh', 'single', 'sins', 'sister', 'sisters', 'sit', 'site', 'sites', 'situation', 'size', 'sjw', 'sjws', 'skills', 'skin', 'skinned', 'skirts', 'slap', 'slave', 'slavery', 'slaves', 'sleep', 'sleeping', 'slut', 'small', 'smart', 'smarter', 'smell', 'smith', 'social', 'socialism', 'socialist', 'society', 'software', 'solar', 'soldiers', 'solution', 'son', 'song', 'songs', 'sons', 'sorry', 'soul', 'source', 'south', 'southern', 'soviet', 'space', 'spaniards', 'spanish', 'speak', 'speaking', 'special', 'species', 'specific', 'speech', 'speed', 'spell', 'spend', 'sperm', 'spoiled', 'spots', 'spouse', 'spread', 'spreading', 'spy', 'st', 'start', 'started', 'startup', 'state', 'states', 'statistics', 'stay', 'steal', 'stealing', 'stephen', 'steps', 'stereotypes', 'stick', 'stock', 'stole', 'stop', 'store', 'stories', 'stormy', 'story', 'straight', 'streets', 'stress', 'strong', 'stronger', 'structure', 'struggle', 'stuck', 'student', 'students', 'studies', 'study', 'studying', 'stupid', 'stupidity', 'style', 'subject', 'successful', 'suck', 'sucking', 'sucks', 'suffer', 'suicide', 'sunni', 'super', 'superior', 'superiority', 'support', 'supporters', 'supporting', 'supposed', 'supremacy', 'supreme', 'surely', 'survive', 'swallow', 'sweden', 'swedes', 'swedish', 'syndrome', 'syria', 'syrian', 'taiwan', 'taiwanese', 'taken', 'taliban', 'talk', 'talking', 'tamil', 'tamilians', 'tamils', 'taste', 'tax', 'teach', 'teacher', 'teachers', 'team', 'tech', 'techniques', 'technology', 'ted', 'teenagers', 'teens', 'tell', 'telling', 'telugu', 'temperature', 'tend', 'tennessee', 'term', 'terms', 'terrible', 'terror', 'terrorism', 'terrorist', 'terrorists', 'test', 'testicles', 'text', 'thanks', 'theists', 'theory', 'theresa', 'thing', 'things', 'think', 'thinking', 'thinks', 'thought', 'thoughts', 'thousands', 'threat', 'threaten', 'threats', 'throw', 'thrown', 'tide', 'tight', 'time', 'times', 'tips', 'tired', 'today', 'toilet', 'toilets', 'told', 'tolerate', 'topic', 'topics', 'torture', 'touch', 'touching', 'tourists', 'toxic', 'track', 'trade', 'traditional', 'training', 'traits', 'trans', 'transfer', 'transgender', 'transgenders', 'trash', 'travel', 'treason', 'treat', 'treated', 'treatment', 'tribe', 'tried', 'troll', 'trolling', 'trolls', 'trudeau', 'true', 'trump', 'trumps', 'truth', 'try', 'trying', 'turkey', 'turkish', 'turks', 'turn', 'turning', 'tv', 'type', 'types', 'ugly', 'uk', 'ukraine', 'unarmed', 'unattractive', 'unborn', 'uncle', 'understand', 'understanding', 'underwear', 'uneducated', 'unfair', 'union', 'unique', 'universe', 'universities', 'university', 'unless', 'unlike', 'upper', 'upsc', 'upset', 'urine', 'usa', 'use', 'used', 'useless', 'users', 'uses', 'using', 'vaccines', 'vagina', 'value', 'various', 'vegan', 'vegans', 'vegetarians', 'victim', 'victims', 'video', 'vietnam', 'vietnamese', 'view', 'views', 'violence', 'violent', 'virat', 'virgin', 'virginity', 'virgins', 'visa', 'visit', 'visiting', 'voice', 'vote', 'voters', 'votes', 'voting', 'vs', 'wall', 'want', 'wants', 'war', 'warming', 'warriors', 'wars', 'waste', 'wasting', 'watch', 'watching', 'water', 'wave', 'way', 'ways', 'weak', 'weaker', 'weapon', 'weapons', 'wear', 'wearing', 'wears', 'web', 'website', 'websites', 'wedding', 'weed', 'weeks', 'weight', 'weinstein', 'weird', 'welfare', 'went', 'west', 'western', 'westerners', 'wet', 'whale', 'white', 'whites', 'wife', 'win', 'wing', 'wingers', 'wipe', 'wish', 'witch', 'wives', 'woman', 'women', 'won', 'word', 'words', 'work', 'workers', 'working', 'works', 'world', 'worse', 'worship', 'worst', 'worth', 'worthless', 'wouldn', 'write', 'writers', 'writing', 'wrong', 'ww', 'year', 'years', 'young', 'youth', 'youtube', 'zealand', 'zionist', 'zionists', 'zuckerberg']\n",
      "All done in 326 s\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix, f1_score, accuracy_score\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/model')\n",
    "from params_lgbm import params_quara\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "\n",
    "# LGBM Args\n",
    "feature_list = np.array(tfidf_vectorizer.get_feature_names())\n",
    "model_type = 'lgb'\n",
    "fold_type = 'stratified'\n",
    "metric = 'accuracy'\n",
    "fold = 2\n",
    "learning_rate = 0.1\n",
    "early_stopping_rounds = 100\n",
    "num_boost_round = 10000\n",
    "seed = 1208\n",
    "params = {\n",
    "    'num_threads': -1,\n",
    "    'metric': 'binary_logloss',\n",
    "    'objective': 'binary',\n",
    "    'boosting_type':'gbdt',\n",
    "    'bagging_freq': 1,\n",
    "    'sigmoid': 1.1,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 9,\n",
    "    'bagging_seed': 1208,\n",
    "    'data_random_seed': 1208,\n",
    "    'feature_fraction_seed': 1208,\n",
    "    'random_seed': 1208,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "# Result\n",
    "select_features = [] # Feature Importanceによって選択したfeature群を入れるリスト\n",
    "\n",
    "with timer(\"LGBM Setting\"):\n",
    "    \n",
    "    prediction = np.array([])\n",
    "    \n",
    "    # testも結合されてるので、trainのみにする\n",
    "    tmp_train = csr_tfidf[list(raw_trn_idx)]\n",
    "\n",
    "    ' KFold '\n",
    "    if fold_type == 'stratified':\n",
    "        folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=seed)\n",
    "        kfold = folds.split(tmp_train, y)\n",
    "    \n",
    "cv_feim = pd.DataFrame() # Feature Importanceの結果ファイルを入れるDF\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(kfold):\n",
    "    \n",
    "    with timer(f\"Validation: {n_fold} | LGBM Train\"):\n",
    "        x_train, y_train = tmp_train[trn_idx], y[trn_idx]\n",
    "        x_val, y_val = tmp_train[val_idx], y[val_idx]\n",
    "    \n",
    "        # Dataset\n",
    "        lgb_train = lgb.Dataset(data=x_train, label=y_train)\n",
    "        lgb_eval = lgb.Dataset(data=x_val, label=y_val)\n",
    "        \n",
    "        estimator = lgb.train(\n",
    "            train_set=lgb_train,\n",
    "            valid_sets=lgb_eval,\n",
    "            params=params,\n",
    "            verbose_eval=200,\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            num_boost_round=num_boost_round\n",
    "        )\n",
    "    \n",
    "    with timer(f\"Validation: {n_fold} | Prediction & Get F1 score\"):\n",
    "        y_pred = estimator.predict(x_val)\n",
    "        score = log_loss(y_val, y_pred)\n",
    "        logger.info(f'Fold No: {n_fold} | {metric}: {score}')\n",
    "        logger.info(f\"Train Shape: {x_train.shape}\")\n",
    "        for thresh in np.arange(0.1, 0.301, 0.01):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            f1 = f1_score(y_val, (y_pred>thresh).astype(int))\n",
    "            logger.info(f\"F1 score at threshold {thresh} is {f1}\")\n",
    "            \n",
    "        ' Feature Importance '\n",
    "        if len(cv_feim):\n",
    "            cv_feim[f'{n_fold}_importance'] = estimator.feature_importance(importance_type='gain')\n",
    "        else:\n",
    "            feim_name = f'{n_fold}_importance'\n",
    "            feim = pd.Series(estimator.feature_importance(importance_type='gain'), name=feim_name, index=feature_list).to_frame().reset_index().rename(columns={'index':'feature'})\n",
    "            cv_feim = feim.copy()\n",
    "            \n",
    "    \n",
    "with timer(\"Save Feature Importance\"):\n",
    "    col_feim = [col for col in cv_feim.columns if col.count('importance')]\n",
    "    cv_feim['avg_importance'] = cv_feim[col_feim].mean(axis=1)\n",
    "    cv_feim.sort_values(by='avg_importance', ascending=False, inplace=True)\n",
    "    from matplotlib import pyplot as plt\n",
    "    import japanize_matplotlib\n",
    "    %matplotlib inline\n",
    "    import seaborn as sns\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    display(cv_feim.head())\n",
    "    sns.barplot(data=cv_feim.iloc[:50, ], x='avg_importance', y='feature')\n",
    "    plt.show()\n",
    "    cv_feim.to_csv(f'../valid/{start_time[4:12]}_{model_type}_TFIDF_f1{f1}_logloss{score}_lr{learning_rate}.csv', index=False)\n",
    "    tmp_features = list(cv_feim[cv_feim['avg_importance']>30]['feature'].values)\n",
    "    print(f'Selece Feature: {len(tmp_features)}')\n",
    "    select_features += tmp_features\n",
    "        \n",
    "select_features = list(set(select_features))\n",
    "print(len(select_features))\n",
    "print(sorted(select_features))\n",
    "print(f'All done in {time.time() - st_time:.0f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importanceにより絞られたlemma_featureのみのsparse_matrixを作成する.  \n",
    "ここで出力されたcsr_matrixが、当初の目的だったFeature Importanceにより上位選択されたlemmaのデータセットとなる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n",
      "1851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1362492, 1851)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = []\n",
    "[id_list.append(id)  for word, id in tfidf_vectorizer.vocabulary_.items() if word in select_features]\n",
    "print(len(id_list))\n",
    "print(len(select_features))\n",
    "tmp_train = csr_tfidf.T[id_list].T\n",
    "tmp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:01:58.493129Z",
     "start_time": "2018-11-10T10:01:58.480016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Make Train Vaidation Set & Tokenizer] done in 1 s\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Make Train Validation\n",
    "# Tokenizer\n",
    "#========================================================================\n",
    "\n",
    "## some config values \n",
    "embed_size = 200 # how big is each word vector\n",
    "max_features = len(id_list) # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = len(id_list) # max number of words in a question to use\n",
    "\n",
    "with timer(\"Make Train Vaidation Set & Tokenizer\"):\n",
    "    \n",
    "    ## split to train and val\n",
    "    train_X, val_X = train_test_split(tmp_train, test_size=0.2, random_state=seed)\n",
    "#     trn_idx, val_idx = list(train_X.index), list(val_X.index)\n",
    "    \n",
    "#     train_X, val_X = tmp_train[trn_idx], tmp_train[val_idx]\n",
    "    ## Get the target values\n",
    "    train_y = y[train_X.index]\n",
    "    val_y = y[val_X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:08:08.365358Z",
     "start_time": "2018-11-10T10:08:08.360417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcuda.so.1: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c00a0fc95400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCuDNNLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCuDNNGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "# import tensorflow as tf\n",
    "# print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# No PreTrain Model\n",
    "#========================================================================\n",
    "def no_pretrain_NN():\n",
    "    with timer(\"Create No PreTrain Model\"):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        x = Embedding(max_features, embed_size)(inp)\n",
    "#         x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        x = GlobalMaxPool1D()(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        print(model.summary())\n",
    "        \n",
    "    with timer(\"Model Fitting\"):\n",
    "        ## Train the model \n",
    "        model.fit(train_X, train_y, batch_size=512, epochs=2,\n",
    "                  validation_data=(val_X, val_y)\n",
    "                 )\n",
    "        \n",
    "    with timer(\"Prediction & Get F1 score\"):\n",
    "        pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "        for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
    "        del model, inp, x\n",
    "        import gc; gc.collect()\n",
    "        time.sleep(10)\n",
    "with timer(f\"Done No PreTrain Model\"):\n",
    "    no_pretrain_NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T11:47:05.117033Z",
     "start_time": "2018-11-10T11:47:05.112139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          9000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 9,142,625\n",
      "Trainable params: 9,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Glove PreTrain Model\n",
    "#========================================================================\n",
    "def glove_pretrain_NN():\n",
    "    with timer(\"Get Glove PreTrain Grad\"):\n",
    "        EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "        def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "        \n",
    "        all_embs = np.stack(embeddings_index.values())\n",
    "        emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "        embed_size = all_embs.shape[1]\n",
    "        \n",
    "        word_index = tokenizer.word_index\n",
    "        nb_words = min(max_features, len(word_index))\n",
    "        embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "        for word, i in word_index.items():\n",
    "            if i >= max_features: continue\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    with timer(\"Create Glove PreTrain Model\"):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "        x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "        x = GlobalMaxPool1D()(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "    with timer(\"Model Fitting\"):\n",
    "        model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))\n",
    "        \n",
    "    with timer(\"Prediction & Get F1 score\"):\n",
    "        pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "        for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\"Make Train Vaidation Set & Tokenizer\"):\n",
    "    \n",
    "    ## fill up the missing values\n",
    "    train_X = tmp_train[\"question_text\"].fillna(\"_na_\").values\n",
    "    \n",
    "    ## Tokenize the sentences\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(train_X))\n",
    "    train_X = tokenizer.texts_to_sequences(train_X)\n",
    "    # test_X = tokenizer.texts_to_sequences(test_X)\n",
    "    \n",
    "    ## Pad the sentences \n",
    "    train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "    # test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "    \n",
    "    ## Get the target values\n",
    "    train_y = train_df['target'].values\n",
    "\n",
    "    # KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    if fold_type == 'stratified':\n",
    "        folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=seed)  # 1\n",
    "        kfold = folds.split(train_X, train_y)\n",
    "\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(kfold):\n",
    "        x_train, x_val = train_X[train_idx], train_X[val_idx]\n",
    "        y_train, y_val = train_y[train_idx], train_y[val_idx] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
