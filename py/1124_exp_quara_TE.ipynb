{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the purpose of this experiment?\n",
    "Target Encodingによるスコアの向上を見る\n",
    "### 2. Why do you this?\n",
    "多様な特徴を作る\n",
    "### 3. Where are the points of technology and techniques?\n",
    "Target Encoding\n",
    "### 4. How do you validate the effectiveness?\n",
    "CV LB\n",
    "### 5. What will you do next?\n",
    "Word Mover Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T09:53:43.606080Z",
     "start_time": "2018-11-10T09:53:43.430947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-24 16:19:16,252 utils 366 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "feat_no = 102\n",
    "is_tfidf = True\n",
    "is_svd = True\n",
    "from main_quara import quara_load_data, cleansing_text\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import os\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from utils import logger_func, get_categorical_features, get_numeric_features, pararell_process\n",
    "logger = logger_func()\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    \"\"\"\n",
    "    Taken from Konstantin Lopuhin https://www.kaggle.com/lopuhin\n",
    "    in script named : Mercari Golf: 0.3875 CV in 75 LOC, 1900 s\n",
    "    https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "def pararell_process(func, arg_list, cpu_cnt=multiprocessing.cpu_count()):\n",
    "    process = Pool(cpu_cnt)\n",
    "    callback = process.map_async(func, arg_list).get(600)\n",
    "    process.close()\n",
    "    process.terminate()\n",
    "    return callback\n",
    "\n",
    "# NLP\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "key = 'qid'\n",
    "qt = 'question_text'\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 89.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train, test = quara_load_data()\n",
    "raw_trn_idx = list(train.index)\n",
    "raw_test_idx = list(test.index)\n",
    "# del train, test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52761, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>\"2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>\"?</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>\"A</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>\"A\"</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>\"All</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>\"America</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>\"American</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>\"An</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  cnt\n",
       "3            !   23\n",
       "9            \"  527\n",
       "145         \"2   11\n",
       "237         \"?   91\n",
       "248         \"A  221\n",
       "249        \"A\"   17\n",
       "446       \"All   41\n",
       "492   \"America   25\n",
       "499  \"American   33\n",
       "520        \"An   22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# def target_encoding(df):\n",
    "df = train\n",
    "word_list = list(chain.from_iterable([doc.split() for doc in df[qt].values]))\n",
    "\n",
    "df_cnt = pd.DataFrame({'word':word_list}).groupby('word').size().reset_index().rename(columns={0:'cnt'})\n",
    "# 10回以上出現している単語\n",
    "df_cnt = df_cnt.query(f\"cnt>=10\")\n",
    "print(df_cnt.shape)\n",
    "display(df_cnt.head(10))\n",
    "\n",
    "word_list = df_cnt['word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_te_dict = {}\n",
    "\n",
    "# これ全単語でやるのは無理だな\n",
    "def parallel_get_te(word):\n",
    "    insincere_ratio = 0\n",
    "    doc_cnt = 0\n",
    "    for args in enumerate(df['question_text'].values):\n",
    "        i  = args[0]\n",
    "        doc = args[1]\n",
    "        if doc.count(word):\n",
    "            insincere_ratio += df[target].values[i]\n",
    "            doc_cnt += 1\n",
    "    insincere_ratio /= doc_cnt\n",
    "    word_te_dict[word] = insincere_ratio\n",
    "    return word_te_dict\n",
    "        \n",
    "with timer(\"Word Target Encoding\"):\n",
    "    p_list = Parallel(n_jobs=-1)([delayed(parallel_get_te)(word) for word in word_list])\n",
    "print(p_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# from collections import defaultdict\n",
    "# Load id Text List\n",
    "train_id_list = list(train[key].values)\n",
    "test_id_list = list(test[key].values)\n",
    "\n",
    "train_text_list = list(train[qt].values)\n",
    "test_text_list = list(test[qt].values)\n",
    "\n",
    "id_list = train_id_list + test_id_list\n",
    "text_list = train_text_list + test_text_list\n",
    "y = train[target]\n",
    "\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "# for args in zip(id_list, tqdm(text_list)):\n",
    "def pararell_id_word(args):\n",
    "    uid = args[0]\n",
    "    doc = args[1]\n",
    "    tmp_dict = defaultdict(list)\n",
    "    for word in doc.split():\n",
    "        if word in word_list:\n",
    "            tmp_dict[uid].append(word)\n",
    "    if uid not in tmp_dict:\n",
    "        tmp_dict[uid] = []\n",
    "    return tmp_dict\n",
    "\n",
    "p_list = Parallel(n_jobs=-1)([delayed(pararell_id_word)(args) for args in zip(id_list, text_list)])\n",
    "\n",
    "id_word_dict = {}\n",
    "[id_word_dict.update({list(p.keys())[0]:\" \".join(list(p.values())[0])}) for p in p_list if p != 0]\n",
    "print(len(id_word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDFのsparse_csr_matrixをLGBMに入力する前に、結果として得られるfeature_importanceにおいてどの単語のGainが大きかった見れるようにしておく必要がある。\n",
    "しかし、50,000カラムのsparse_csr_matrixをtoarrayするとそれだけでallocate_memoryとなる。\n",
    "よって、まずはmatrixのインデックスに対応する各単語をvectorizer.vocabrary_ or vectorizer.get_feature_names()で取得する。\n",
    "その後、LGBMのfeature_importance()がカラム順で出力されるのを確認した上で、対応づける。\n",
    "なお、50,000カラムではLGBMの学習の時間がかかりすぎるので、5,000~10,000カラムに分割し、それぞれLGBMにかけて単語を選別していく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9012691774819092\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "seed = 1208\n",
    "\n",
    "\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool = True):\n",
    "        if(seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    \n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    oof_train = np.zeros((len(raw_train_idx),))\n",
    "    oof_test = np.zeros((len(raw_test_idx),))\n",
    "    oof_test_skf = np.empty((5, len(raw_test_idx)))\n",
    "\n",
    "    fold = 2\n",
    "    ' KFold '\n",
    "    folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=seed)  # 1\n",
    "    base_train = pd.DataFrame({'index':raw_train_idx})\n",
    "    kfold = folds.split(base_train, y)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "        y_pred = clf.predict(x_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "ridge_params = {'alpha':30.0, 'fit_intercept':True, 'normalize':False, 'copy_X':True,\n",
    "                'max_iter':None, 'tol':0.001, 'solver':'auto', 'random_state':seed}\n",
    "\n",
    "#Ridge oof method from Faron's kernel\n",
    "ridge = SklearnWrapper(clf=Ridge, seed = seed, params = ridge_params)\n",
    "ridge_oof_train, ridge_oof_test = get_oof(ridge, csr_tfidf[raw_train_idx], y, csr_tfidf[raw_test_idx])\n",
    "ridge_oof_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM Setting] done in 0 s\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.887448\n",
      "[400]\tvalid_0's auc: 0.89717\n",
      "[600]\tvalid_0's auc: 0.900281\n",
      "[800]\tvalid_0's auc: 0.901587\n",
      "[1000]\tvalid_0's auc: 0.902618\n",
      "[1200]\tvalid_0's auc: 0.903304\n",
      "[1400]\tvalid_0's auc: 0.903469\n",
      "Early stopping, best iteration is:\n",
      "[1483]\tvalid_0's auc: 0.903559\n",
      "[Validation: 0 | LGBM Train] done in 71 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-22 19:18:29,877 utils 88 [INFO]    [<module>] Fold No: 0 | accuracy: 0.15368822729258605 \n",
      "INFO:utils:Fold No: 0 | accuracy: 0.15368822729258605\n",
      "2018-11-22 19:18:29,878 utils 89 [INFO]    [<module>] Train Shape: (653061, 677) \n",
      "INFO:utils:Train Shape: (653061, 677)\n",
      "2018-11-22 19:18:29,972 utils 93 [INFO]    [<module>] F1 score at threshold 0.1 is 0.4391473724926784 \n",
      "INFO:utils:F1 score at threshold 0.1 is 0.4391473724926784\n",
      "2018-11-22 19:18:30,065 utils 93 [INFO]    [<module>] F1 score at threshold 0.11 is 0.4623496334524084 \n",
      "INFO:utils:F1 score at threshold 0.11 is 0.4623496334524084\n",
      "2018-11-22 19:18:30,157 utils 93 [INFO]    [<module>] F1 score at threshold 0.12 is 0.4738053042315704 \n",
      "INFO:utils:F1 score at threshold 0.12 is 0.4738053042315704\n",
      "2018-11-22 19:18:30,248 utils 93 [INFO]    [<module>] F1 score at threshold 0.13 is 0.4870659367595392 \n",
      "INFO:utils:F1 score at threshold 0.13 is 0.4870659367595392\n",
      "2018-11-22 19:18:30,340 utils 93 [INFO]    [<module>] F1 score at threshold 0.14 is 0.49671979101963015 \n",
      "INFO:utils:F1 score at threshold 0.14 is 0.49671979101963015\n",
      "2018-11-22 19:18:30,431 utils 93 [INFO]    [<module>] F1 score at threshold 0.15 is 0.5032254657783801 \n",
      "INFO:utils:F1 score at threshold 0.15 is 0.5032254657783801\n",
      "2018-11-22 19:18:30,522 utils 93 [INFO]    [<module>] F1 score at threshold 0.16 is 0.5098520376631402 \n",
      "INFO:utils:F1 score at threshold 0.16 is 0.5098520376631402\n",
      "2018-11-22 19:18:30,612 utils 93 [INFO]    [<module>] F1 score at threshold 0.17 is 0.5172652969406119 \n",
      "INFO:utils:F1 score at threshold 0.17 is 0.5172652969406119\n",
      "2018-11-22 19:18:30,701 utils 93 [INFO]    [<module>] F1 score at threshold 0.18 is 0.5218111115389057 \n",
      "INFO:utils:F1 score at threshold 0.18 is 0.5218111115389057\n",
      "2018-11-22 19:18:30,790 utils 93 [INFO]    [<module>] F1 score at threshold 0.19 is 0.526471464019851 \n",
      "INFO:utils:F1 score at threshold 0.19 is 0.526471464019851\n",
      "2018-11-22 19:18:30,878 utils 93 [INFO]    [<module>] F1 score at threshold 0.2 is 0.5291996822357565 \n",
      "INFO:utils:F1 score at threshold 0.2 is 0.5291996822357565\n",
      "2018-11-22 19:18:30,967 utils 93 [INFO]    [<module>] F1 score at threshold 0.21 is 0.533569645741133 \n",
      "INFO:utils:F1 score at threshold 0.21 is 0.533569645741133\n",
      "2018-11-22 19:18:31,056 utils 93 [INFO]    [<module>] F1 score at threshold 0.22 is 0.5361571357961017 \n",
      "INFO:utils:F1 score at threshold 0.22 is 0.5361571357961017\n",
      "2018-11-22 19:18:31,143 utils 93 [INFO]    [<module>] F1 score at threshold 0.23 is 0.5367431051870041 \n",
      "INFO:utils:F1 score at threshold 0.23 is 0.5367431051870041\n",
      "2018-11-22 19:18:31,231 utils 93 [INFO]    [<module>] F1 score at threshold 0.24 is 0.5373731470763421 \n",
      "INFO:utils:F1 score at threshold 0.24 is 0.5373731470763421\n",
      "2018-11-22 19:18:31,318 utils 93 [INFO]    [<module>] F1 score at threshold 0.25 is 0.5365216793788222 \n",
      "INFO:utils:F1 score at threshold 0.25 is 0.5365216793788222\n",
      "2018-11-22 19:18:31,404 utils 93 [INFO]    [<module>] F1 score at threshold 0.26 is 0.5358770064721138 \n",
      "INFO:utils:F1 score at threshold 0.26 is 0.5358770064721138\n",
      "2018-11-22 19:18:31,491 utils 93 [INFO]    [<module>] F1 score at threshold 0.27 is 0.535079401279543 \n",
      "INFO:utils:F1 score at threshold 0.27 is 0.535079401279543\n",
      "2018-11-22 19:18:31,575 utils 93 [INFO]    [<module>] F1 score at threshold 0.28 is 0.5336544338769224 \n",
      "INFO:utils:F1 score at threshold 0.28 is 0.5336544338769224\n",
      "2018-11-22 19:18:31,661 utils 93 [INFO]    [<module>] F1 score at threshold 0.29 is 0.5318456300787755 \n",
      "INFO:utils:F1 score at threshold 0.29 is 0.5318456300787755\n",
      "2018-11-22 19:18:31,747 utils 93 [INFO]    [<module>] F1 score at threshold 0.3 is 0.5293998634328925 \n",
      "INFO:utils:F1 score at threshold 0.3 is 0.5293998634328925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation: 0 | Prediction & Get F1 score] done in 10 s\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.889362\n",
      "[400]\tvalid_0's auc: 0.898276\n",
      "[600]\tvalid_0's auc: 0.901738\n",
      "[800]\tvalid_0's auc: 0.903439\n",
      "[1000]\tvalid_0's auc: 0.904308\n",
      "[1200]\tvalid_0's auc: 0.904942\n",
      "[1400]\tvalid_0's auc: 0.90513\n",
      "[1600]\tvalid_0's auc: 0.905334\n",
      "[1800]\tvalid_0's auc: 0.905396\n",
      "Early stopping, best iteration is:\n",
      "[1789]\tvalid_0's auc: 0.905414\n",
      "[Validation: 1 | LGBM Train] done in 86 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-22 19:20:06,432 utils 88 [INFO]    [<module>] Fold No: 1 | accuracy: 0.1531323603936086 \n",
      "INFO:utils:Fold No: 1 | accuracy: 0.1531323603936086\n",
      "2018-11-22 19:20:06,434 utils 89 [INFO]    [<module>] Train Shape: (653061, 677) \n",
      "INFO:utils:Train Shape: (653061, 677)\n",
      "2018-11-22 19:20:06,526 utils 93 [INFO]    [<module>] F1 score at threshold 0.1 is 0.44896255579843947 \n",
      "INFO:utils:F1 score at threshold 0.1 is 0.44896255579843947\n",
      "2018-11-22 19:20:06,617 utils 93 [INFO]    [<module>] F1 score at threshold 0.11 is 0.46278242662290897 \n",
      "INFO:utils:F1 score at threshold 0.11 is 0.46278242662290897\n",
      "2018-11-22 19:20:06,709 utils 93 [INFO]    [<module>] F1 score at threshold 0.12 is 0.4751911652939991 \n",
      "INFO:utils:F1 score at threshold 0.12 is 0.4751911652939991\n",
      "2018-11-22 19:20:06,801 utils 93 [INFO]    [<module>] F1 score at threshold 0.13 is 0.48500431211664474 \n",
      "INFO:utils:F1 score at threshold 0.13 is 0.48500431211664474\n",
      "2018-11-22 19:20:06,890 utils 93 [INFO]    [<module>] F1 score at threshold 0.14 is 0.49690259877456155 \n",
      "INFO:utils:F1 score at threshold 0.14 is 0.49690259877456155\n",
      "2018-11-22 19:20:06,978 utils 93 [INFO]    [<module>] F1 score at threshold 0.15 is 0.505487964989059 \n",
      "INFO:utils:F1 score at threshold 0.15 is 0.505487964989059\n",
      "2018-11-22 19:20:07,068 utils 93 [INFO]    [<module>] F1 score at threshold 0.16 is 0.5148911017141818 \n",
      "INFO:utils:F1 score at threshold 0.16 is 0.5148911017141818\n",
      "2018-11-22 19:20:07,157 utils 93 [INFO]    [<module>] F1 score at threshold 0.17 is 0.5207291890528203 \n",
      "INFO:utils:F1 score at threshold 0.17 is 0.5207291890528203\n",
      "2018-11-22 19:20:07,246 utils 93 [INFO]    [<module>] F1 score at threshold 0.18 is 0.5260547813551177 \n",
      "INFO:utils:F1 score at threshold 0.18 is 0.5260547813551177\n",
      "2018-11-22 19:20:07,334 utils 93 [INFO]    [<module>] F1 score at threshold 0.19 is 0.5290393831226458 \n",
      "INFO:utils:F1 score at threshold 0.19 is 0.5290393831226458\n",
      "2018-11-22 19:20:07,422 utils 93 [INFO]    [<module>] F1 score at threshold 0.2 is 0.5353289742541887 \n",
      "INFO:utils:F1 score at threshold 0.2 is 0.5353289742541887\n",
      "2018-11-22 19:20:07,509 utils 93 [INFO]    [<module>] F1 score at threshold 0.21 is 0.5369821249582359 \n",
      "INFO:utils:F1 score at threshold 0.21 is 0.5369821249582359\n",
      "2018-11-22 19:20:07,597 utils 93 [INFO]    [<module>] F1 score at threshold 0.22 is 0.5380916764611603 \n",
      "INFO:utils:F1 score at threshold 0.22 is 0.5380916764611603\n",
      "2018-11-22 19:20:07,684 utils 93 [INFO]    [<module>] F1 score at threshold 0.23 is 0.5397121009618544 \n",
      "INFO:utils:F1 score at threshold 0.23 is 0.5397121009618544\n",
      "2018-11-22 19:20:07,771 utils 93 [INFO]    [<module>] F1 score at threshold 0.24 is 0.5398049140213858 \n",
      "INFO:utils:F1 score at threshold 0.24 is 0.5398049140213858\n",
      "2018-11-22 19:20:07,858 utils 93 [INFO]    [<module>] F1 score at threshold 0.25 is 0.5394608121942895 \n",
      "INFO:utils:F1 score at threshold 0.25 is 0.5394608121942895\n",
      "2018-11-22 19:20:07,944 utils 93 [INFO]    [<module>] F1 score at threshold 0.26 is 0.5381628809894683 \n",
      "INFO:utils:F1 score at threshold 0.26 is 0.5381628809894683\n",
      "2018-11-22 19:20:08,031 utils 93 [INFO]    [<module>] F1 score at threshold 0.27 is 0.537532845678574 \n",
      "INFO:utils:F1 score at threshold 0.27 is 0.537532845678574\n",
      "2018-11-22 19:20:08,116 utils 93 [INFO]    [<module>] F1 score at threshold 0.28 is 0.5373737862902249 \n",
      "INFO:utils:F1 score at threshold 0.28 is 0.5373737862902249\n",
      "2018-11-22 19:20:08,202 utils 93 [INFO]    [<module>] F1 score at threshold 0.29 is 0.535229332905788 \n",
      "INFO:utils:F1 score at threshold 0.29 is 0.535229332905788\n",
      "2018-11-22 19:20:08,289 utils 93 [INFO]    [<module>] F1 score at threshold 0.3 is 0.5328396611233134 \n",
      "INFO:utils:F1 score at threshold 0.3 is 0.5328396611233134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation: 1 | Prediction & Get F1 score] done in 11 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0_importance</th>\n",
       "      <th>1_importance</th>\n",
       "      <th>avg_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>people</td>\n",
       "      <td>35443.058798</td>\n",
       "      <td>35338.862383</td>\n",
       "      <td>35390.960591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>trump</td>\n",
       "      <td>32731.477361</td>\n",
       "      <td>31596.615681</td>\n",
       "      <td>32164.046521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>women</td>\n",
       "      <td>27641.806129</td>\n",
       "      <td>27767.994430</td>\n",
       "      <td>27704.900279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>muslims</td>\n",
       "      <td>23292.306484</td>\n",
       "      <td>21780.204910</td>\n",
       "      <td>22536.255697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>liberals</td>\n",
       "      <td>16786.553867</td>\n",
       "      <td>17583.272237</td>\n",
       "      <td>17184.913052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  0_importance  1_importance  avg_importance\n",
       "458    people  35443.058798  35338.862383    35390.960591\n",
       "611     trump  32731.477361  31596.615681    32164.046521\n",
       "663     women  27641.806129  27767.994430    27704.900279\n",
       "425   muslims  23292.306484  21780.204910    22536.255697\n",
       "360  liberals  16786.553867  17583.272237    17184.913052"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAK7CAYAAABbO01TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZlZVf0/Yqgioxbi+SkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4646c0f550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selece Feature: 673\n",
      "[Save Feature Importance] done in 0 s\n",
      "673\n",
      "['10', '12th', '2017', '2018', 'abortion', 'abuse', 'accept', 'acceptable', 'account', 'act', 'actually', 'admission', 'admit', 'advantages', 'advice', 'affect', 'afraid', 'africa', 'african', 'africans', 'agree', 'air', 'allah', 'allow', 'allowed', 'amazon', 'america', 'american', 'americans', 'android', 'angry', 'answer', 'answers', 'anti', 'app', 'application', 'apply', 'apps', 'arab', 'arabs', 'aren', 'arrogant', 'ashamed', 'asian', 'asians', 'ask', 'asking', 'ass', 'assume', 'atheist', 'atheists', 'attack', 'attacks', 'attracted', 'attractive', 'available', 'aware', 'away', 'bad', 'ban', 'bangalore', 'bank', 'barack', 'beat', 'beautiful', 'behave', 'believe', 'benefits', 'bengali', 'best', 'biased', 'bible', 'big', 'bjp', 'black', 'blacks', 'blame', 'blind', 'book', 'books', 'born', 'boy', 'boys', 'brahmins', 'britain', 'british', 'build', 'business', 'buy', 'called', 'calling', 'came', 'canadians', 'car', 'card', 'care', 'career', 'caste', 'castrate', 'castrated', 'causes', 'cbse', 'chances', 'change', 'characteristics', 'cheat', 'child', 'children', 'china', 'chinese', 'christian', 'christianity', 'christians', 'citizens', 'claim', 'claiming', 'claims', 'class', 'clearly', 'clinton', 'coaching', 'code', 'college', 'colleges', 'come', 'comes', 'commit', 'committed', 'communist', 'community', 'companies', 'company', 'compared', 'complain', 'computer', 'congress', 'conservative', 'conservatives', 'consider', 'considered', 'continue', 'control', 'convince', 'corrupt', 'cost', 'countries', 'country', 'course', 'courses', 'cousin', 'crazy', 'created', 'crime', 'crimes', 'culture', 'data', 'date', 'daughter', 'death', 'defend', 'degree', 'democracy', 'democrat', 'democratic', 'democrats', 'deny', 'deserve', 'design', 'despite', 'destroy', 'destroying', 'development', 'dick', 'did', 'didn', 'die', 'difference', 'differences', 'different', 'digital', 'dislike', 'does', 'doesn', 'dog', 'don', 'donald', 'dont', 'download', 'dumb', 'earn', 'earth', 'easily', 'east', 'eat', 'educated', 'effect', 'effective', 'effects', 'election', 'energy', 'engineer', 'engineering', 'enjoy', 'especially', 'ethnic', 'europe', 'european', 'europeans', 'evidence', 'evil', 'exam', 'examples', 'experience', 'facebook', 'fact', 'factors', 'fair', 'fake', 'false', 'family', 'far', 'fat', 'favorite', 'fbi', 'feel', 'female', 'females', 'feminism', 'feminist', 'feminists', 'field', 'fight', 'finally', 'force', 'forced', 'freedom', 'friend', 'fuck', 'fucking', 'function', 'future', 'gandhi', 'gay', 'gays', 'gender', 'generally', 'genocide', 'germans', 'germany', 'girl', 'girls', 'given', 'giving', 'god', 'going', 'good', 'google', 'gop', 'government', 'great', 'greeks', 'groups', 'gun', 'guns', 'guy', 'guys', 'half', 'happen', 'happens', 'happy', 'hate', 'hated', 'hatred', 'having', 'hell', 'hillary', 'hindi', 'hindu', 'hindus', 'history', 'hitler', 'holocaust', 'homosexual', 'homosexuality', 'homosexuals', 'human', 'idiots', 'ignorant', 'ignore', 'iit', 'illegal', 'immigrants', 'immigration', 'impact', 'important', 'improve', 'incest', 'increase', 'india', 'indian', 'indians', 'indonesians', 'inferior', 'innocent', 'insist', 'instead', 'intelligent', 'interesting', 'interview', 'invest', 'iphone', 'iq', 'iran', 'iranians', 'isis', 'islam', 'islamic', 'isn', 'israel', 'israeli', 'israelis', 'japanese', 'jealous', 'jee', 'jesus', 'jew', 'jewish', 'jews', 'job', 'just', 'justify', 'kashmir', 'kashmiri', 'kick', 'kids', 'kill', 'killed', 'killing', 'kim', 'know', 'known', 'korea', 'korean', 'koreans', 'lack', 'land', 'laptop', 'law', 'laws', 'leaders', 'learn', 'learning', 'leave', 'left', 'leftist', 'leftists', 'let', 'lgbt', 'liberal', 'liberals', 'lie', 'lies', 'life', 'light', 'like', 'likely', 'little', 'live', 'lives', 'living', 'long', 'look', 'looking', 'lot', 'love', 'low', 'lying', 'main', 'major', 'majority', 'make', 'makes', 'making', 'male', 'males', 'man', 'management', 'market', 'marketing', 'marks', 'married', 'marry', 'mass', 'mba', 'mean', 'meaning', 'mechanical', 'media', 'medical', 'members', 'men', 'mental', 'mentally', 'mexicans', 'middle', 'military', 'million', 'millions', 'minorities', 'minority', 'mobile', 'modern', 'modi', 'mom', 'month', 'months', 'mother', 'movie', 'ms', 'mueller', 'muhammad', 'murder', 'music', 'muslim', 'muslims', 'narendra', 'nation', 'nations', 'native', 'nazi', 'nazis', 'new', 'news', 'nice', 'non', 'north', 'nra', 'number', 'obama', 'obsessed', 'obvious', 'offended', 'ok', 'okay', 'old', 'ones', 'online', 'options', 'pakistan', 'pakistani', 'pakistanis', 'palestinian', 'palestinians', 'parents', 'party', 'peace', 'penis', 'people', 'person', 'phd', 'phone', 'physics', 'pm', 'police', 'political', 'politically', 'politicians', 'poor', 'population', 'possible', 'prefer', 'prepare', 'president', 'pretend', 'price', 'prince', 'problem', 'process', 'product', 'program', 'programming', 'project', 'proof', 'propaganda', 'protect', 'proud', 'prove', 'public', 'pursue', 'putin', 'question', 'questions', 'quora', 'quorans', 'race', 'racial', 'racism', 'racist', 'rahul', 'rank', 'rape', 'raped', 'raping', 'read', 'real', 'realise', 'realize', 'really', 'reason', 'recommend', 'refugees', 'refuse', 'religion', 'religious', 'republican', 'republicans', 'required', 'research', 'respect', 'responsible', 'rest', 'rich', 'right', 'rights', 'role', 'rude', 'run', 'russia', 'russian', 'russians', 'said', 'salary', 'saudi', 'save', 'say', 'saying', 'says', 'school', 'scope', 'score', 'secretly', 'secular', 'seen', 'sense', 'series', 'service', 'sex', 'sexual', 'sexually', 'shit', 'shooting', 'shouldn', 'sikhs', 'simply', 'sister', 'skills', 'skin', 'slave', 'slavery', 'slaves', 'smarter', 'society', 'software', 'soldiers', 'son', 'song', 'south', 'speak', 'speed', 'spread', 'stand', 'start', 'starting', 'state', 'states', 'steal', 'stock', 'stop', 'straight', 'student', 'study', 'studying', 'stupid', 'suck', 'superior', 'support', 'supporters', 'supporting', 'syria', 'talk', 'tamil', 'tamils', 'tell', 'tend', 'terrorism', 'terrorist', 'terrorists', 'test', 'things', 'think', 'thousands', 'time', 'tips', 'training', 'transgender', 'travel', 'treated', 'true', 'trump', 'truth', 'try', 'trying', 'turkish', 'turks', 'turn', 'tv', 'type', 'types', 'ugly', 'uk', 'understand', 'united', 'university', 'upsc', 'usa', 'use', 'used', 'using', 'value', 've', 'victims', 'video', 'vietnamese', 'violence', 'violent', 'visa', 'vote', 'voted', 'voters', 'vs', 'want', 'wants', 'war', 'water', 'way', 'ways', 'wear', 'wearing', 'web', 'website', 'weight', 'west', 'western', 'white', 'whites', 'wife', 'wing', 'wives', 'woman', 'women', 'won', 'work', 'working', 'world', 'worse', 'worship', 'worth', 'write', 'writing', 'wrong', 'year', 'young', 'youtube']\n",
      "All done in 178 s\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/model')\n",
    "from params_lgbm import params_quara\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "\n",
    "# Args\n",
    "feature_list = np.array(tfidf_vectorizer.get_feature_names())\n",
    "feat_split_size = 4\n",
    "\n",
    "# LGBM Args\n",
    "model_type = 'lgb'\n",
    "fold_type = 'stratified'\n",
    "metric = 'accuracy'\n",
    "fold = 2\n",
    "learning_rate = 0.1\n",
    "early_stopping_rounds = 100\n",
    "num_boost_round = 5000\n",
    "seed = 1208\n",
    "params = {\n",
    "    'num_threads': -1,\n",
    "    'metric': 'auc',\n",
    "    'objective': 'binary',\n",
    "    'boosting_type':'gbdt',\n",
    "    'bagging_freq': 1,\n",
    "    'sigmoid': 1.1,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 9,\n",
    "    'bagging_seed': 1208,\n",
    "    'data_random_seed': 1208,\n",
    "    'feature_fraction_seed': 1208,\n",
    "    'random_seed': 1208,\n",
    "    'verbose': 1\n",
    "}\n",
    "# params['device'] = 'gpu'\n",
    "# params['gpu_platform_id'] = 0\n",
    "# params['gpu_device_id'] = 0\n",
    "\n",
    "\n",
    "# Result\n",
    "select_features = [] # Feature Importanceによって選択したfeature群を入れるリスト\n",
    "\n",
    "with timer(\"LGBM Setting\"):\n",
    "    \n",
    "    prediction = np.array([])\n",
    "    \n",
    "    from scipy.sparse import hstack, csr_matrix\n",
    "    # testも結合されてるので、trainのみにする\n",
    "#     tmp_train = hstack([csr_tfidf[list(raw_trn_idx)], ridge_oof_train]).toarray()\n",
    "    tmp_train = csr_tfidf[list(raw_trn_idx)]\n",
    "    \n",
    "' KFold '\n",
    "if fold_type == 'stratified':\n",
    "    folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=seed)\n",
    "    kfold = folds.split(tmp_train, y)\n",
    "\n",
    "cv_feim = pd.DataFrame() # Feature Importanceの結果ファイルを入れるDF\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(kfold):\n",
    "    \n",
    "    with timer(f\"Validation: {n_fold} | LGBM Train\"):\n",
    "        x_train, y_train = tmp_train[trn_idx], y[trn_idx]\n",
    "        x_val, y_val = tmp_train[val_idx], y[val_idx]\n",
    "    \n",
    "        # Dataset\n",
    "        lgb_train = lgb.Dataset(data=x_train, label=y_train)\n",
    "        lgb_eval = lgb.Dataset(data=x_val, label=y_val)\n",
    "        \n",
    "        estimator = lgb.train(\n",
    "            train_set=lgb_train,\n",
    "            valid_sets=lgb_eval,\n",
    "            params=params,\n",
    "            verbose_eval=200,\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            num_boost_round=num_boost_round\n",
    "        )\n",
    "    \n",
    "    with timer(f\"Validation: {n_fold} | Prediction & Get F1 score\"):\n",
    "        y_pred = estimator.predict(x_val)\n",
    "        y_pred = (y_pred + ridge_oof_train[val_idx].ravel())/2\n",
    "        score = log_loss(y_val, y_pred)\n",
    "        logger.info(f'Fold No: {n_fold} | {metric}: {score}')\n",
    "        logger.info(f\"Train Shape: {x_train.shape}\")\n",
    "        for thresh in np.arange(0.1, 0.301, 0.01):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            f1 = f1_score(y_val, (y_pred>thresh).astype(int))\n",
    "            logger.info(f\"F1 score at threshold {thresh} is {f1}\")\n",
    "            \n",
    "        ' Feature Importance '\n",
    "        if len(cv_feim):\n",
    "            cv_feim[f'{n_fold}_importance'] = estimator.feature_importance(importance_type='gain')\n",
    "        else:\n",
    "            feim_name = f'{n_fold}_importance'\n",
    "            feim = pd.Series(estimator.feature_importance(importance_type='gain'), name=feim_name, index=feature_list).to_frame().reset_index().rename(columns={'index':'feature'})\n",
    "            cv_feim = feim.copy()\n",
    "            \n",
    "    \n",
    "with timer(\"Save Feature Importance\"):\n",
    "    col_feim = [col for col in cv_feim.columns if col.count('importance')]\n",
    "    cv_feim['avg_importance'] = cv_feim[col_feim].mean(axis=1)\n",
    "    cv_feim.sort_values(by='avg_importance', ascending=False, inplace=True)\n",
    "    from matplotlib import pyplot as plt\n",
    "    import japanize_matplotlib\n",
    "    %matplotlib inline\n",
    "    import seaborn as sns\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    display(cv_feim.head())\n",
    "    sns.barplot(data=cv_feim.iloc[:50, ], x='avg_importance', y='feature')\n",
    "    plt.show()\n",
    "    cv_feim.to_csv(f'../valid/{start_time[4:12]}_{model_type}_TFIDF_f1{f1}_auc{score}_lr{learning_rate}.csv', index=False)\n",
    "    tmp_features = list(cv_feim[cv_feim['avg_importance']>30]['feature'].values)\n",
    "    print(f'Selece Feature: {len(tmp_features)}')\n",
    "    select_features += tmp_features\n",
    "        \n",
    "select_features = list(set(select_features))\n",
    "print(len(select_features))\n",
    "print(sorted(select_features))\n",
    "print(f'All done in {time.time() - st_time:.0f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importanceにより絞られたlemma_featureのみのsparse_matrixを作成する.  \n",
    "ここで出力されたcsr_matrixが、当初の目的だったFeature Importanceにより上位選択されたlemmaのデータセットとなる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n",
      "1851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1362492, 1851)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = []\n",
    "[id_list.append(id)  for word, id in tfidf_vectorizer.vocabulary_.items() if word in select_features]\n",
    "print(len(id_list))\n",
    "print(len(select_features))\n",
    "tmp_train = csr_tfidf.T[id_list].T\n",
    "tmp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:01:58.493129Z",
     "start_time": "2018-11-10T10:01:58.480016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Make Train Vaidation Set & Tokenizer] done in 1 s\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Make Train Validation\n",
    "# Tokenizer\n",
    "#========================================================================\n",
    "\n",
    "## some config values \n",
    "embed_size = 200 # how big is each word vector\n",
    "max_features = len(id_list) # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = len(id_list) # max number of words in a question to use\n",
    "\n",
    "with timer(\"Make Train Vaidation Set & Tokenizer\"):\n",
    "    \n",
    "    ## split to train and val\n",
    "#     train_X, val_X = train_test_split(train, test_size=0.2, random_state=seed)\n",
    "#     trn_idx, val_idx = list(train_X.index), list(val_X.index)\n",
    "    \n",
    "    train_X, val_X = tmp_train[trn_idx], tmp_train[val_idx]\n",
    "    ## Get the target values\n",
    "    train_y = train['target'].values[trn_idx]\n",
    "    val_y = train['target'].values[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:08:08.365358Z",
     "start_time": "2018-11-10T10:08:08.360417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 1851)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 1851, 300)         555300    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 1851, 128)         186880    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 744,261\n",
      "Trainable params: 744,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[Create No PreTrain Model] done in 0 s\n",
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU,XLA_CPU,XLA_GPU], Registered kernels:\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n\n\t [[node bidirectional_1/CudnnRNN (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](bidirectional_1/transpose, bidirectional_1/ExpandDims_1, bidirectional_1/ExpandDims_2, bidirectional_1/concat)]]\n\nCaused by op 'bidirectional_1/CudnnRNN', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-62-b5784077a58a>\", line 46, in <module>\n    no_pretrain_NN()\n  File \"<ipython-input-62-b5784077a58a>\", line 21, in no_pretrain_NN\n    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 427, in __call__\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 522, in call\n    y = self.forward_layer.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1544, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1435, in __call__\n    seed=self._seed)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 922, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 116, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU,XLA_CPU,XLA_GPU], Registered kernels:\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n\n\t [[node bidirectional_1/CudnnRNN (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](bidirectional_1/transpose, bidirectional_1/ExpandDims_1, bidirectional_1/ExpandDims_2, bidirectional_1/concat)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU,XLA_CPU,XLA_GPU], Registered kernels:\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n\n\t [[{{node bidirectional_1/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](bidirectional_1/transpose, bidirectional_1/ExpandDims_1, bidirectional_1/ExpandDims_2, bidirectional_1/concat)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-61008ddda45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Done No PreTrain Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mno_pretrain_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-61008ddda45f>\u001b[0m in \u001b[0;36mno_pretrain_NN\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m## Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         model.fit(train_X, train_y, batch_size=512, epochs=2,\n\u001b[0;32m---> 34\u001b[0;31m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                  )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU,XLA_CPU,XLA_GPU], Registered kernels:\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n\n\t [[node bidirectional_1/CudnnRNN (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](bidirectional_1/transpose, bidirectional_1/ExpandDims_1, bidirectional_1/ExpandDims_2, bidirectional_1/concat)]]\n\nCaused by op 'bidirectional_1/CudnnRNN', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-62-b5784077a58a>\", line 46, in <module>\n    no_pretrain_NN()\n  File \"<ipython-input-62-b5784077a58a>\", line 21, in no_pretrain_NN\n    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 427, in __call__\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 522, in call\n    y = self.forward_layer.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1544, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1435, in __call__\n    seed=self._seed)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 922, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 116, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU,XLA_CPU,XLA_GPU], Registered kernels:\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n\n\t [[node bidirectional_1/CudnnRNN (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"lstm\", seed=87654321, seed2=0](bidirectional_1/transpose, bidirectional_1/ExpandDims_1, bidirectional_1/ExpandDims_2, bidirectional_1/concat)]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())\n",
    "\n",
    "#========================================================================\n",
    "# No PreTrain Model\n",
    "#========================================================================\n",
    "def no_pretrain_NN():\n",
    "    with timer(\"Create No PreTrain Model\"):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        x = Embedding(max_features, embed_size)(inp)\n",
    "#         x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "        x = GlobalMaxPool1D()(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        print(model.summary())\n",
    "        \n",
    "    with timer(\"Model Fitting\"):\n",
    "        ## Train the model \n",
    "        model.fit(train_X, train_y, batch_size=512, epochs=2,\n",
    "                  validation_data=(val_X, val_y)\n",
    "                 )\n",
    "        \n",
    "    with timer(\"Prediction & Get F1 score\"):\n",
    "        pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "        for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
    "        del model, inp, x\n",
    "        import gc; gc.collect()\n",
    "        time.sleep(10)\n",
    "with timer(f\"Done No PreTrain Model\"):\n",
    "    no_pretrain_NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T11:47:05.117033Z",
     "start_time": "2018-11-10T11:47:05.112139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          9000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 9,142,625\n",
      "Trainable params: 9,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Glove PreTrain Model\n",
    "#========================================================================\n",
    "def glove_pretrain_NN():\n",
    "    with timer(\"Get Glove PreTrain Grad\"):\n",
    "        EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "        def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "        \n",
    "        all_embs = np.stack(embeddings_index.values())\n",
    "        emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "        embed_size = all_embs.shape[1]\n",
    "        \n",
    "        word_index = tokenizer.word_index\n",
    "        nb_words = min(max_features, len(word_index))\n",
    "        embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "        for word, i in word_index.items():\n",
    "            if i >= max_features: continue\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    with timer(\"Create Glove PreTrain Model\"):\n",
    "        inp = Input(shape=(maxlen,))\n",
    "        x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "        x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "        x = GlobalMaxPool1D()(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "    with timer(\"Model Fitting\"):\n",
    "        model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))\n",
    "        \n",
    "    with timer(\"Prediction & Get F1 score\"):\n",
    "        pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "        for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "            thresh = np.round(thresh, 2)\n",
    "            print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\"Make Train Vaidation Set & Tokenizer\"):\n",
    "    \n",
    "    ## fill up the missing values\n",
    "    train_X = tmp_train[\"question_text\"].fillna(\"_na_\").values\n",
    "    \n",
    "    ## Tokenize the sentences\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(train_X))\n",
    "    train_X = tokenizer.texts_to_sequences(train_X)\n",
    "    # test_X = tokenizer.texts_to_sequences(test_X)\n",
    "    \n",
    "    ## Pad the sentences \n",
    "    train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "    # test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "    \n",
    "    ## Get the target values\n",
    "    train_y = train_df['target'].values\n",
    "\n",
    "    # KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    if fold_type == 'stratified':\n",
    "        folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=seed)  # 1\n",
    "        kfold = folds.split(train_X, train_y)\n",
    "\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(kfold):\n",
    "        x_train, x_val = train_X[train_idx], train_X[val_idx]\n",
    "        y_train, y_val = train_y[train_idx], train_y[val_idx] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
