{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T09:53:43.606080Z",
     "start_time": "2018-11-10T09:53:43.430947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-17 11:06:45,902 utils 353 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import os\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from utils import logger_func, get_categorical_features, get_numeric_features, pararell_process\n",
    "logger = logger_func()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "\n",
    "key = 'qid'\n",
    "qt = 'question_text'\n",
    "seed = 1208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T09:59:40.218753Z",
     "start_time": "2018-11-10T09:59:40.181039Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "### add for TensorBoard\n",
    "import keras.callbacks\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())\n",
    "\n",
    "old_session = KTF.get_session()\n",
    "\n",
    "session = tf.Session('')\n",
    "KTF.set_session(session)\n",
    "KTF.set_learning_phase(1)\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:01:58.493129Z",
     "start_time": "2018-11-10T10:01:58.480016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 1.12 s, total: 2min 13s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train = utils.read_pkl_gzip(path='../input/1116_train_wordnet_lemma_dict.gz')\n",
    "# train_df = utils.read_df_pkl('../input/train*.p')[['qid', 'target']]\n",
    "# tmp = train.copy()\n",
    "tmp_train = utils.read_df_pkl('../input/wn_bagging_train*.p')\n",
    "\n",
    "# # for uid, value in tmp.items():\n",
    "# def pararell_val_join(args):\n",
    "#     uid = args[0]\n",
    "#     value = args[1]\n",
    "#     df_dict = {}\n",
    "#     np.random.seed(seed)\n",
    "#     val_len = int(len(value)*0.5)\n",
    "#     try:\n",
    "#         value = np.random.choice(a=value, size=val_len)\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "#     df_dict[uid] = \" \".join(value)\n",
    "#     return df_dict\n",
    "# tmp_dict = {}\n",
    "# p_list = pararell_process(pararell_val_join, tmp.items())\n",
    "# [tmp_dict.update(p) for p in p_list]\n",
    "# tmp_train = pd.Series(tmp_dict).to_frame()\n",
    "# tmp_train = tmp_train.join(train_df.set_index('qid'))\n",
    "# tmp_train.rename(columns={0:qt}, inplace=True)\n",
    "\n",
    "## split to train and val\n",
    "train_df, val_df = train_test_split(tmp_train, test_size=0.2, random_state=seed)\n",
    "\n",
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "# Current Best 30000\n",
    "max_features = 30000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
    "# test_X = test_df[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "# test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "# test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:08:08.365358Z",
     "start_time": "2018-11-10T10:08:08.360417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 100, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 100, 128)          187392    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,189,473\n",
      "Trainable params: 6,189,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "# x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:21:50.258378Z",
     "start_time": "2018-11-10T10:21:50.254689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/2\n",
      "1044897/1044897 [==============================] - 53s 51us/step - loss: 0.1665 - acc: 0.9429 - val_loss: 0.1493 - val_acc: 0.9456\n",
      "Epoch 2/2\n",
      "1044897/1044897 [==============================] - 51s 49us/step - loss: 0.1423 - acc: 0.9478 - val_loss: 0.1488 - val_acc: 0.9456\n"
     ]
    }
   ],
   "source": [
    "## Train the model \n",
    "tb_cb = keras.callbacks.TensorBoard(log_dir=\"../tflog/\", histogram_freq=1, write_grads=True, write_graph=True, write_images=True)\n",
    "model.fit(train_X, train_y, batch_size=512, epochs=2,\n",
    "          ## add 1 line\n",
    "#           callbacks=[tb_cb],\n",
    "          validation_data=(val_X, val_y)\n",
    "         )\n",
    "\n",
    "### add for TensorBoard\n",
    "KTF.set_session(old_session)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T10:25:14.360222Z",
     "start_time": "2018-11-10T10:23:09.691923Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225/261225 [==============================] - 4s 14us/step\n",
      "F1 score at threshold 0.1 is 0.4135253040157242\n",
      "F1 score at threshold 0.11 is 0.4262421320476764\n",
      "F1 score at threshold 0.12 is 0.43750873759261844\n",
      "F1 score at threshold 0.13 is 0.44815238926150097\n",
      "F1 score at threshold 0.14 is 0.4574009598193281\n",
      "F1 score at threshold 0.15 is 0.4658498638662\n",
      "F1 score at threshold 0.16 is 0.4732842793271448\n",
      "F1 score at threshold 0.17 is 0.4797539934783506\n",
      "F1 score at threshold 0.18 is 0.48527384915502214\n",
      "F1 score at threshold 0.19 is 0.49118607181719254\n",
      "F1 score at threshold 0.2 is 0.4962114458905332\n",
      "F1 score at threshold 0.21 is 0.5014047189420068\n",
      "F1 score at threshold 0.22 is 0.5064865243916692\n",
      "F1 score at threshold 0.23 is 0.5104067214053848\n",
      "F1 score at threshold 0.24 is 0.513340318218367\n",
      "F1 score at threshold 0.25 is 0.515124422589778\n",
      "F1 score at threshold 0.26 is 0.5171986756640634\n",
      "F1 score at threshold 0.27 is 0.5182937803717893\n",
      "F1 score at threshold 0.28 is 0.5209701473012218\n",
      "F1 score at threshold 0.29 is 0.5219729031914611\n",
      "F1 score at threshold 0.3 is 0.5221877110060771\n",
      "F1 score at threshold 0.31 is 0.5214984516730152\n",
      "F1 score at threshold 0.32 is 0.5214631702021045\n",
      "F1 score at threshold 0.33 is 0.5215939321899586\n",
      "F1 score at threshold 0.34 is 0.5213062868651992\n",
      "F1 score at threshold 0.35 is 0.5217213354382272\n",
      "F1 score at threshold 0.36 is 0.5209205642167781\n",
      "F1 score at threshold 0.37 is 0.52009656004828\n",
      "F1 score at threshold 0.38 is 0.5194455494017931\n",
      "F1 score at threshold 0.39 is 0.5177362241411443\n",
      "F1 score at threshold 0.4 is 0.5163856791058912\n",
      "F1 score at threshold 0.41 is 0.513882201893757\n",
      "F1 score at threshold 0.42 is 0.5120861197194585\n",
      "F1 score at threshold 0.43 is 0.5095021723989255\n",
      "F1 score at threshold 0.44 is 0.5054071353973655\n",
      "F1 score at threshold 0.45 is 0.49826775975028303\n",
      "F1 score at threshold 0.46 is 0.4936422226093015\n",
      "F1 score at threshold 0.47 is 0.4888747391135166\n",
      "F1 score at threshold 0.48 is 0.48434357943119793\n",
      "F1 score at threshold 0.49 is 0.4781370902985619\n",
      "F1 score at threshold 0.5 is 0.47183594763970776\n"
     ]
    }
   ],
   "source": [
    "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
    "# del model, inp, x\n",
    "# import gc; gc.collect()\n",
    "# time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T11:47:05.117033Z",
     "start_time": "2018-11-10T11:47:05.112139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          9000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 9,142,625\n",
      "Trainable params: 9,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "utils.start()\n",
    "EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "utils.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/2\n",
      "1044897/1044897 [==============================] - 55s 52us/step - loss: 0.1569 - acc: 0.9444 - val_loss: 0.1464 - val_acc: 0.9465\n",
      "Epoch 2/2\n",
      "1044897/1044897 [==============================] - 52s 50us/step - loss: 0.1385 - acc: 0.9481 - val_loss: 0.1462 - val_acc: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f833bed2390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.start()\n",
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))\n",
    "utils.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225/261225 [==============================] - 3s 12us/step\n",
      "F1 score at threshold 0.1 is 0.4836587701403056\n",
      "F1 score at threshold 0.11 is 0.4921298200792431\n",
      "F1 score at threshold 0.12 is 0.49971978748683005\n",
      "F1 score at threshold 0.13 is 0.5064435379195253\n",
      "F1 score at threshold 0.14 is 0.5119274809160306\n",
      "F1 score at threshold 0.15 is 0.5158870255957635\n",
      "F1 score at threshold 0.16 is 0.5197421434327155\n",
      "F1 score at threshold 0.17 is 0.5233119178470985\n",
      "F1 score at threshold 0.18 is 0.5260098808485906\n",
      "F1 score at threshold 0.19 is 0.5271225778593405\n",
      "F1 score at threshold 0.2 is 0.5296788574259061\n",
      "F1 score at threshold 0.21 is 0.5306179696485175\n",
      "F1 score at threshold 0.22 is 0.5303883189987714\n",
      "F1 score at threshold 0.23 is 0.5311681508643269\n",
      "F1 score at threshold 0.24 is 0.5314081131461372\n",
      "F1 score at threshold 0.25 is 0.530355854772782\n",
      "F1 score at threshold 0.26 is 0.5300137467542386\n",
      "F1 score at threshold 0.27 is 0.5282445588144107\n",
      "F1 score at threshold 0.28 is 0.5259681021737078\n",
      "F1 score at threshold 0.29 is 0.5241788758019725\n",
      "F1 score at threshold 0.3 is 0.5217813765182187\n",
      "F1 score at threshold 0.31 is 0.5203465476503019\n",
      "F1 score at threshold 0.32 is 0.5182523044158265\n",
      "F1 score at threshold 0.33 is 0.5162268729147711\n",
      "F1 score at threshold 0.34 is 0.5131691319646091\n",
      "F1 score at threshold 0.35 is 0.5097387995156547\n",
      "F1 score at threshold 0.36 is 0.5070718386780563\n",
      "F1 score at threshold 0.37 is 0.5021835611574649\n",
      "F1 score at threshold 0.38 is 0.4983832722569519\n",
      "F1 score at threshold 0.39 is 0.49445232638509945\n",
      "F1 score at threshold 0.4 is 0.4899926416482708\n",
      "F1 score at threshold 0.41 is 0.4851713859910581\n",
      "F1 score at threshold 0.42 is 0.47919655667144906\n",
      "F1 score at threshold 0.43 is 0.47407237571172\n",
      "F1 score at threshold 0.44 is 0.4662919170381856\n",
      "F1 score at threshold 0.45 is 0.45930758046135106\n",
      "F1 score at threshold 0.46 is 0.45079415755447366\n",
      "F1 score at threshold 0.47 is 0.4418002266472398\n",
      "F1 score at threshold 0.48 is 0.4215105439781248\n",
      "F1 score at threshold 0.49 is 0.41470058249172354\n",
      "F1 score at threshold 0.5 is 0.40870043586813926\n"
     ]
    }
   ],
   "source": [
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
